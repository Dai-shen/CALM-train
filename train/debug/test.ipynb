{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /nfs/v100-022/jiyunjie/anaconda3/envs/hwg001/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so\n",
      "CUDA SETUP: CUDA runtime path found: /nfs/a100-006/hanweiguang/local/cuda-11.8/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /nfs/v100-022/jiyunjie/anaconda3/envs/hwg001/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/v100-022/jiyunjie/anaconda3/envs/hwg001/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /nfs/v100-022/jiyunjie/anaconda3/envs/hwg001 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/nfs/v100-022/jiyunjie/anaconda3/envs/hwg001/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "from typing import Dict, List, Tuple, Union\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from flask import Flask, render_template, request\n",
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path='/nfs/a100-80G-17/jiyunjie/finetuned_ckpt/on_belle_tokenizer50k_openinstr_zh/zh_alpaca_gpt3.5_gpt4_sharegpt_epoch=2-step=20652'\n",
    "ckpt_path='/nfs/a100-006/hanweiguang/saved_model/boxue_1_bs-8_lr-3e-4_wm-1e-2_epoch-10_lora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and tokenizer\n",
    "load_type = torch.float16\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.bos_token_id = 1\n",
    "tokenizer.eos_token_id = 2\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, torch_dtype=load_type\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model, ckpt_path, torch_dtype=load_type\n",
    ")\n",
    "model.eval()\n",
    "model.to('cuda:0')\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_per_token(input_ids: torch.Tensor) -> Tuple[List[float], float]:\n",
    "    \"\"\"\n",
    "    input_ids: [1, sen_len]\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "        logits = outputs.logits\n",
    "        probs = logits.softmax(dim=-1)\n",
    "    # Select the probabilities of the generated tokens\n",
    "    # [1, sen_len, 1]\n",
    "    generated_token_probs = torch.gather(\n",
    "        probs[:, :-1, :], 2, input_ids[:, 1:, None])  # skip the first token_id\n",
    "    return generated_token_probs[0, ..., 0].tolist(), outputs.loss.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.3,\n",
    "    top_p=0.85,\n",
    "    top_k=30,\n",
    "    num_beams=1,\n",
    "    bos_token_id=1,\n",
    "    eos_token_id=2,\n",
    "    pad_token_id=0,\n",
    "    max_new_tokens=200,  # max_length=max_new_tokens+input_sequence\n",
    "    min_new_tokens=1,  # min_length=min_new_tokens+input_sequence\n",
    "    repetition_penalty=1.2,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_and_get_probability(input_text: str, generation_config: GenerationConfig):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        getattr(model, 'module', model).device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids=input_ids,\n",
    "                                generation_config=generation_config)\n",
    "    token_ids = output[0].tolist()\n",
    "    tokens = [tokenizer.decode([token_id], skip_special_tokens=False)\n",
    "              for token_id in token_ids]\n",
    "    token_probs_list, loss = get_probability_per_token(output)\n",
    "\n",
    "    # The probability of <s> is set to 0\n",
    "    tokens_with_probs = [{'token': tokens[0], 'prob': 0.0}]\n",
    "    for token, prob in zip(tokens[1:], token_probs_list):\n",
    "        tokens_with_probs.append({\n",
    "            'token': token,\n",
    "            'prob': prob\n",
    "        })\n",
    "\n",
    "    return tokens_with_probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_and_get_probability('你是谁', generation_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算训练集的loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/nfs/a100-006/hanweiguang/Projects/BELLE/data/boxue/corpus_1_train.jsonl') as f:\n",
    "    corpus_1 = f.readlines()\n",
    "    corpus_1 = [json.loads(s)['text'] for s in corpus_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(79458, 4096, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(\n",
       "                in_features=4096, out_features=11008, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): Linear(\n",
       "                in_features=11008, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): Linear(\n",
       "                in_features=4096, out_features=11008, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=79458, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(\n",
    "    base_model, ckpt_path, torch_dtype=load_type\n",
    ")\n",
    "model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:47<00:00,  8.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model.eval()\n",
    "losses = [\n",
    "    get_probability_per_token(\n",
    "        tokenizer.encode(\n",
    "            sample, \n",
    "            return_tensors='pt'\n",
    "        ).to(\n",
    "            getattr(model, 'module', model).device\n",
    "        )\n",
    "    )[1]\n",
    "    for sample in tqdm(corpus_1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.13150146484375"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证zero 3 + lora保存的模型是否带上了lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path='/nfs/a100-80G-17/jiyunjie/finetuned_ckpt/on_belle_tokenizer50k_openinstr_zh/zh_alpaca_gpt3.5_gpt4_sharegpt_epoch=2-step=20652'\n",
    "ckpt_path='/nfs/a100-006/hanweiguang/saved_model/boxue_1_bs-32_lr-3e-4_wm-1e-2_epoch-100_lora'\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, torch_dtype=load_type\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model, ckpt_path, torch_dtype=load_type\n",
    ")\n",
    "model.eval()\n",
    "model.to('cuda:0')\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/nfs/a100-006/hanweiguang/Projects/BELLE/data/boxue/corpus.jsonl') as f:\n",
    "    corpus = f.readlines()\n",
    "    corpus = [json.loads(s)['text'] for s in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 297/297 [00:47<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model.eval()\n",
    "losses = [\n",
    "    get_probability_per_token(\n",
    "        tokenizer.encode(\n",
    "            sample, \n",
    "            return_tensors='pt'\n",
    "        ).to(\n",
    "            getattr(model, 'module', model).device\n",
    "        )\n",
    "    )[1]\n",
    "    for sample in tqdm(corpus)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.12377683080808"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 297/297 [00:46<00:00,  6.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model.eval()\n",
    "losses = [\n",
    "    get_probability_per_token(\n",
    "        tokenizer.encode(\n",
    "            sample, \n",
    "            return_tensors='pt'\n",
    "        ).to(\n",
    "            getattr(model, 'module', model).device\n",
    "        )\n",
    "    )[1]\n",
    "    for sample in tqdm(corpus)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.12377683080808"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_parameters = torch.load('/nfs/a100-006/hanweiguang/saved_model/boxue_debug_debug/checkpoint-1/adapter_model.bin', map_location='cpu')\n",
    "lora_parameters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight': tensor([[ 0.0080, -0.0104, -0.0047,  ..., -0.0059,  0.0042,  0.0138],\n",
       "         [-0.0001,  0.0142,  0.0116,  ...,  0.0026, -0.0109, -0.0138],\n",
       "         [-0.0013,  0.0007, -0.0032,  ..., -0.0151, -0.0011,  0.0013],\n",
       "         ...,\n",
       "         [-0.0083, -0.0054,  0.0052,  ..., -0.0090,  0.0097,  0.0013],\n",
       "         [-0.0129,  0.0059,  0.0037,  ..., -0.0035,  0.0016, -0.0118],\n",
       "         [ 0.0020,  0.0120,  0.0019,  ..., -0.0076,  0.0022,  0.0102]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.weight': tensor([[-0.0147, -0.0044,  0.0051,  ..., -0.0148,  0.0014, -0.0082],\n",
       "         [ 0.0116,  0.0108, -0.0071,  ..., -0.0027,  0.0082,  0.0075],\n",
       "         [-0.0129,  0.0132, -0.0149,  ...,  0.0025,  0.0097, -0.0071],\n",
       "         ...,\n",
       "         [ 0.0103, -0.0047,  0.0005,  ..., -0.0081,  0.0087, -0.0150],\n",
       "         [-0.0142, -0.0156, -0.0131,  ...,  0.0114,  0.0010,  0.0054],\n",
       "         [-0.0008, -0.0078,  0.0015,  ..., -0.0060,  0.0005, -0.0023]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight': tensor([[ 1.4954e-02, -9.6664e-03,  9.1248e-03,  ..., -9.1476e-03,\n",
       "          -1.3596e-02, -2.9068e-03],\n",
       "         [ 9.4070e-03,  1.2970e-02,  3.5286e-03,  ...,  2.8191e-03,\n",
       "          -7.0305e-03,  1.0529e-02],\n",
       "         [-1.5152e-02, -9.2316e-03,  4.2877e-03,  ...,  8.6975e-03,\n",
       "          -6.5804e-03, -9.8991e-04],\n",
       "         ...,\n",
       "         [-1.1665e-02, -1.2718e-02,  8.6136e-03,  ..., -1.0674e-02,\n",
       "           6.1874e-03,  1.0643e-02],\n",
       "         [-1.4000e-02, -4.2801e-03,  2.6226e-05,  ..., -2.0237e-03,\n",
       "           7.2708e-03,  3.9482e-03],\n",
       "         [-4.4327e-03,  2.5539e-03, -7.7286e-03,  ...,  5.4817e-03,\n",
       "          -1.5022e-02, -2.0504e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.weight': tensor([[ 0.0116, -0.0107, -0.0110,  ..., -0.0111,  0.0137, -0.0082],\n",
       "         [-0.0043, -0.0086, -0.0129,  ..., -0.0057, -0.0103,  0.0113],\n",
       "         [ 0.0116,  0.0076,  0.0088,  ..., -0.0046, -0.0136,  0.0126],\n",
       "         ...,\n",
       "         [-0.0103,  0.0118, -0.0030,  ..., -0.0116,  0.0097, -0.0152],\n",
       "         [-0.0095,  0.0120,  0.0153,  ...,  0.0113,  0.0084, -0.0103],\n",
       "         [-0.0016, -0.0083, -0.0086,  ...,  0.0047, -0.0097,  0.0051]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.weight': tensor([[-0.0092, -0.0141,  0.0144,  ...,  0.0137,  0.0081,  0.0037],\n",
       "         [-0.0028,  0.0009, -0.0118,  ..., -0.0032, -0.0118, -0.0146],\n",
       "         [-0.0013, -0.0097, -0.0036,  ..., -0.0004,  0.0021,  0.0103],\n",
       "         ...,\n",
       "         [-0.0155, -0.0125, -0.0100,  ...,  0.0051,  0.0043, -0.0122],\n",
       "         [ 0.0002, -0.0080, -0.0138,  ...,  0.0073,  0.0096, -0.0077],\n",
       "         [-0.0096,  0.0122, -0.0031,  ...,  0.0130, -0.0004, -0.0132]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.mlp.down_proj.lora_A.weight': tensor([[ 0.0003,  0.0025, -0.0053,  ..., -0.0077, -0.0090, -0.0010],\n",
       "         [-0.0073,  0.0072,  0.0010,  ...,  0.0029,  0.0081,  0.0076],\n",
       "         [ 0.0045,  0.0037, -0.0010,  ...,  0.0040, -0.0032, -0.0039],\n",
       "         ...,\n",
       "         [ 0.0061,  0.0002,  0.0036,  ..., -0.0008,  0.0086, -0.0057],\n",
       "         [ 0.0055, -0.0008, -0.0070,  ..., -0.0015,  0.0079, -0.0015],\n",
       "         [-0.0062,  0.0027, -0.0035,  ..., -0.0010, -0.0034,  0.0051]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.mlp.up_proj.lora_A.weight': tensor([[-0.0148,  0.0021,  0.0148,  ..., -0.0021, -0.0024,  0.0013],\n",
       "         [ 0.0120, -0.0117,  0.0083,  ...,  0.0093, -0.0008, -0.0075],\n",
       "         [ 0.0006,  0.0077, -0.0140,  ..., -0.0103, -0.0010, -0.0027],\n",
       "         ...,\n",
       "         [ 0.0035,  0.0153, -0.0093,  ...,  0.0090,  0.0042, -0.0080],\n",
       "         [-0.0075, -0.0075,  0.0026,  ..., -0.0070, -0.0077,  0.0104],\n",
       "         [-0.0126, -0.0094,  0.0021,  ...,  0.0121, -0.0069, -0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.0.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight': tensor([[-0.0043,  0.0102,  0.0035,  ...,  0.0140, -0.0005,  0.0061],\n",
       "         [ 0.0103, -0.0064,  0.0134,  ...,  0.0078, -0.0016, -0.0048],\n",
       "         [ 0.0011, -0.0074,  0.0006,  ..., -0.0129,  0.0140,  0.0135],\n",
       "         ...,\n",
       "         [-0.0127,  0.0120,  0.0154,  ..., -0.0136,  0.0114, -0.0029],\n",
       "         [-0.0113,  0.0104,  0.0058,  ...,  0.0140, -0.0142, -0.0037],\n",
       "         [ 0.0038, -0.0112,  0.0051,  ..., -0.0031,  0.0020, -0.0047]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.weight': tensor([[-0.0079, -0.0010,  0.0136,  ...,  0.0030, -0.0048, -0.0049],\n",
       "         [ 0.0147, -0.0152, -0.0148,  ...,  0.0014,  0.0140, -0.0139],\n",
       "         [ 0.0113,  0.0088,  0.0126,  ..., -0.0001,  0.0110, -0.0111],\n",
       "         ...,\n",
       "         [-0.0074, -0.0003,  0.0126,  ...,  0.0039,  0.0135,  0.0082],\n",
       "         [-0.0006, -0.0069, -0.0019,  ..., -0.0017, -0.0082,  0.0058],\n",
       "         [ 0.0078, -0.0033,  0.0065,  ..., -0.0148, -0.0123,  0.0089]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight': tensor([[ 0.0126, -0.0070, -0.0112,  ..., -0.0098,  0.0017,  0.0067],\n",
       "         [-0.0104, -0.0027,  0.0111,  ...,  0.0017, -0.0068,  0.0136],\n",
       "         [ 0.0146,  0.0087,  0.0001,  ...,  0.0071,  0.0106,  0.0018],\n",
       "         ...,\n",
       "         [-0.0028, -0.0131, -0.0087,  ...,  0.0147,  0.0092,  0.0019],\n",
       "         [-0.0009,  0.0087, -0.0151,  ..., -0.0136,  0.0142,  0.0150],\n",
       "         [ 0.0016, -0.0012,  0.0037,  ...,  0.0005,  0.0117, -0.0066]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.weight': tensor([[-0.0073,  0.0024,  0.0034,  ..., -0.0028, -0.0147,  0.0103],\n",
       "         [-0.0065,  0.0078, -0.0028,  ...,  0.0151, -0.0015,  0.0153],\n",
       "         [ 0.0066, -0.0010,  0.0017,  ...,  0.0033,  0.0077, -0.0154],\n",
       "         ...,\n",
       "         [ 0.0005, -0.0008,  0.0126,  ...,  0.0102, -0.0032, -0.0116],\n",
       "         [-0.0078,  0.0076,  0.0128,  ...,  0.0088,  0.0095,  0.0026],\n",
       "         [ 0.0020, -0.0110, -0.0051,  ..., -0.0061,  0.0015, -0.0080]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.weight': tensor([[-9.1743e-04,  1.4069e-02,  6.9466e-03,  ..., -8.6899e-03,\n",
       "          -7.8278e-03,  1.0109e-02],\n",
       "         [ 9.2239e-03,  9.4986e-03, -6.7902e-03,  ..., -1.4114e-02,\n",
       "           4.1847e-03,  7.0534e-03],\n",
       "         [-1.3718e-02,  8.8806e-03,  7.1220e-03,  ...,  2.0065e-03,\n",
       "          -2.7733e-03, -9.7046e-03],\n",
       "         ...,\n",
       "         [ 9.6619e-05, -1.3496e-02,  6.9351e-03,  ..., -2.2435e-04,\n",
       "           4.1733e-03, -2.3632e-03],\n",
       "         [-7.2575e-04, -4.1046e-03, -6.0234e-03,  ...,  1.4057e-03,\n",
       "           7.0648e-03, -5.3139e-03],\n",
       "         [-8.8348e-03, -1.4023e-02,  1.0353e-02,  ...,  8.6060e-03,\n",
       "           9.9030e-03,  1.0061e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.mlp.down_proj.lora_A.weight': tensor([[-0.0015,  0.0055,  0.0047,  ...,  0.0093, -0.0028,  0.0045],\n",
       "         [ 0.0090, -0.0015,  0.0068,  ..., -0.0018, -0.0027,  0.0058],\n",
       "         [ 0.0080,  0.0056,  0.0092,  ..., -0.0057, -0.0078,  0.0069],\n",
       "         ...,\n",
       "         [ 0.0038, -0.0092, -0.0042,  ...,  0.0002,  0.0032, -0.0018],\n",
       "         [-0.0051,  0.0011, -0.0021,  ..., -0.0081, -0.0071, -0.0072],\n",
       "         [-0.0095,  0.0017, -0.0034,  ..., -0.0011, -0.0078, -0.0089]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.mlp.up_proj.lora_A.weight': tensor([[ 0.0146,  0.0012,  0.0057,  ..., -0.0084, -0.0067, -0.0116],\n",
       "         [ 0.0071, -0.0029,  0.0079,  ...,  0.0026,  0.0108,  0.0038],\n",
       "         [-0.0111,  0.0094,  0.0049,  ..., -0.0117,  0.0001,  0.0100],\n",
       "         ...,\n",
       "         [-0.0137, -0.0134,  0.0040,  ...,  0.0066, -0.0071,  0.0101],\n",
       "         [-0.0052, -0.0150, -0.0077,  ...,  0.0153,  0.0058,  0.0047],\n",
       "         [-0.0032,  0.0146, -0.0006,  ..., -0.0085, -0.0056, -0.0148]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.1.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight': tensor([[-0.0114, -0.0118,  0.0154,  ..., -0.0051,  0.0140, -0.0009],\n",
       "         [-0.0153, -0.0135, -0.0081,  ..., -0.0080,  0.0129,  0.0052],\n",
       "         [ 0.0029, -0.0075, -0.0060,  ..., -0.0053,  0.0131, -0.0084],\n",
       "         ...,\n",
       "         [-0.0030,  0.0093,  0.0002,  ...,  0.0148,  0.0091,  0.0136],\n",
       "         [-0.0127, -0.0074,  0.0018,  ...,  0.0019, -0.0148,  0.0062],\n",
       "         [-0.0137,  0.0117,  0.0075,  ..., -0.0023,  0.0149, -0.0104]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.weight': tensor([[-0.0008, -0.0095,  0.0051,  ...,  0.0125, -0.0025, -0.0031],\n",
       "         [-0.0053,  0.0113, -0.0127,  ...,  0.0091,  0.0080, -0.0125],\n",
       "         [ 0.0150, -0.0067,  0.0035,  ...,  0.0110, -0.0117, -0.0008],\n",
       "         ...,\n",
       "         [ 0.0116,  0.0003, -0.0016,  ...,  0.0148,  0.0087,  0.0027],\n",
       "         [ 0.0139,  0.0061,  0.0011,  ..., -0.0103, -0.0029,  0.0008],\n",
       "         [ 0.0097,  0.0083,  0.0071,  ..., -0.0003, -0.0025, -0.0080]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight': tensor([[ 0.0024,  0.0027, -0.0040,  ...,  0.0039,  0.0116,  0.0050],\n",
       "         [-0.0069,  0.0075, -0.0030,  ...,  0.0143,  0.0009,  0.0154],\n",
       "         [-0.0089,  0.0114,  0.0032,  ...,  0.0011,  0.0009, -0.0131],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0090, -0.0103,  ...,  0.0018, -0.0124, -0.0122],\n",
       "         [-0.0074,  0.0090,  0.0084,  ...,  0.0111,  0.0127, -0.0020],\n",
       "         [-0.0073, -0.0099, -0.0091,  ..., -0.0120,  0.0068, -0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.weight': tensor([[ 5.2643e-03,  1.6928e-03,  7.0114e-03,  ..., -3.7594e-03,\n",
       "          -7.7057e-03, -4.0359e-03],\n",
       "         [-8.5297e-03, -1.5457e-02,  3.8548e-03,  ..., -6.3133e-04,\n",
       "           4.6997e-03,  5.5275e-03],\n",
       "         [ 1.9026e-03, -9.2163e-03, -1.4949e-04,  ..., -5.2338e-03,\n",
       "          -3.9101e-03,  1.1093e-02],\n",
       "         ...,\n",
       "         [-6.6032e-03, -8.6365e-03, -7.4463e-03,  ...,  5.0964e-03,\n",
       "           8.2855e-03, -4.7340e-03],\n",
       "         [-1.0672e-03, -8.2092e-03, -9.8801e-03,  ...,  1.5480e-02,\n",
       "          -1.2291e-02, -2.9316e-03],\n",
       "         [-1.5427e-02, -1.3552e-03,  1.2102e-03,  ..., -7.0953e-03,\n",
       "           1.1780e-02, -9.0659e-05]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.weight': tensor([[-0.0122,  0.0153,  0.0119,  ..., -0.0092,  0.0123,  0.0092],\n",
       "         [-0.0025,  0.0011, -0.0125,  ...,  0.0037,  0.0150,  0.0129],\n",
       "         [-0.0107,  0.0099,  0.0025,  ..., -0.0113,  0.0143, -0.0154],\n",
       "         ...,\n",
       "         [ 0.0084,  0.0117,  0.0111,  ..., -0.0128,  0.0066,  0.0154],\n",
       "         [ 0.0065,  0.0009, -0.0107,  ...,  0.0092, -0.0076, -0.0075],\n",
       "         [ 0.0126,  0.0107, -0.0075,  ..., -0.0093,  0.0032, -0.0005]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.mlp.down_proj.lora_A.weight': tensor([[-0.0051,  0.0042,  0.0084,  ..., -0.0037,  0.0033,  0.0004],\n",
       "         [-0.0038, -0.0088, -0.0074,  ..., -0.0029,  0.0093,  0.0067],\n",
       "         [ 0.0028,  0.0061,  0.0038,  ...,  0.0087, -0.0089, -0.0024],\n",
       "         ...,\n",
       "         [ 0.0028, -0.0043, -0.0014,  ...,  0.0021, -0.0051, -0.0035],\n",
       "         [-0.0046,  0.0017, -0.0054,  ...,  0.0050,  0.0094,  0.0007],\n",
       "         [ 0.0015,  0.0040, -0.0066,  ..., -0.0045, -0.0036,  0.0028]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.mlp.up_proj.lora_A.weight': tensor([[-0.0109, -0.0097, -0.0145,  ..., -0.0044,  0.0037,  0.0045],\n",
       "         [-0.0147,  0.0019, -0.0079,  ...,  0.0084,  0.0009,  0.0048],\n",
       "         [ 0.0010, -0.0006,  0.0019,  ...,  0.0131,  0.0117, -0.0138],\n",
       "         ...,\n",
       "         [ 0.0148,  0.0137,  0.0044,  ..., -0.0033,  0.0149, -0.0050],\n",
       "         [-0.0014, -0.0139,  0.0143,  ..., -0.0125, -0.0035,  0.0133],\n",
       "         [-0.0123,  0.0017,  0.0142,  ...,  0.0028, -0.0075,  0.0056]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.2.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight': tensor([[-1.5610e-02,  3.6335e-03,  7.7820e-03,  ...,  5.3673e-03,\n",
       "           1.4511e-02, -1.2718e-02],\n",
       "         [-1.0590e-02, -1.2749e-02, -2.1095e-03,  ...,  3.7708e-03,\n",
       "           1.8454e-03,  7.8735e-03],\n",
       "         [ 7.7095e-03, -1.1129e-03,  7.8201e-03,  ..., -2.0466e-03,\n",
       "          -8.1024e-03, -5.6505e-04],\n",
       "         ...,\n",
       "         [-1.2276e-02, -8.9722e-03,  1.2636e-03,  ...,  3.8128e-03,\n",
       "          -6.1989e-03,  3.5172e-03],\n",
       "         [-8.2970e-04, -5.9967e-03,  2.5272e-05,  ...,  8.2321e-03,\n",
       "          -1.5549e-02,  7.4043e-03],\n",
       "         [-8.4152e-03, -5.4283e-03, -4.2801e-03,  ...,  3.5820e-03,\n",
       "           1.3512e-02,  2.5311e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.weight': tensor([[-0.0118, -0.0136, -0.0031,  ..., -0.0081, -0.0040, -0.0116],\n",
       "         [ 0.0148,  0.0050,  0.0148,  ..., -0.0149,  0.0005, -0.0033],\n",
       "         [-0.0075,  0.0027,  0.0008,  ..., -0.0018, -0.0148, -0.0037],\n",
       "         ...,\n",
       "         [-0.0040,  0.0072,  0.0100,  ...,  0.0080, -0.0009,  0.0110],\n",
       "         [ 0.0014,  0.0006,  0.0132,  ..., -0.0018, -0.0120,  0.0139],\n",
       "         [ 0.0089, -0.0153, -0.0007,  ...,  0.0014, -0.0131,  0.0147]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight': tensor([[ 0.0085, -0.0109, -0.0089,  ...,  0.0021, -0.0110,  0.0148],\n",
       "         [ 0.0086,  0.0088,  0.0013,  ..., -0.0059,  0.0028, -0.0081],\n",
       "         [-0.0046, -0.0135, -0.0117,  ..., -0.0076, -0.0014,  0.0040],\n",
       "         ...,\n",
       "         [-0.0104, -0.0077,  0.0155,  ...,  0.0027,  0.0116,  0.0019],\n",
       "         [-0.0052,  0.0047, -0.0132,  ..., -0.0152,  0.0112, -0.0048],\n",
       "         [ 0.0133, -0.0075,  0.0062,  ..., -0.0031, -0.0035,  0.0146]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.weight': tensor([[-8.9931e-04,  1.0290e-03,  2.6188e-03,  ...,  7.6599e-03,\n",
       "          -1.4847e-02, -9.3579e-05],\n",
       "         [-1.2962e-02,  1.0742e-02, -5.6190e-03,  ...,  1.2455e-03,\n",
       "          -1.0735e-02,  2.1172e-04],\n",
       "         [-1.0040e-02, -1.4702e-02, -8.4686e-03,  ...,  3.9787e-03,\n",
       "           2.1172e-04, -1.2299e-02],\n",
       "         ...,\n",
       "         [-7.1869e-03, -1.4305e-02,  6.3095e-03,  ...,  6.2408e-03,\n",
       "           3.0079e-03,  3.3436e-03],\n",
       "         [ 8.0414e-03, -3.6788e-04, -9.6817e-03,  ..., -4.9858e-03,\n",
       "          -4.0550e-03, -1.1772e-02],\n",
       "         [-3.9959e-04,  8.5297e-03,  1.4236e-02,  ...,  8.7051e-03,\n",
       "           1.0193e-02,  2.4986e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.weight': tensor([[ 0.0073, -0.0003, -0.0084,  ...,  0.0145, -0.0119, -0.0091],\n",
       "         [-0.0044,  0.0104, -0.0050,  ..., -0.0020,  0.0002,  0.0027],\n",
       "         [ 0.0023,  0.0147,  0.0026,  ...,  0.0056, -0.0108,  0.0129],\n",
       "         ...,\n",
       "         [-0.0022, -0.0026, -0.0019,  ...,  0.0116,  0.0100, -0.0033],\n",
       "         [-0.0015,  0.0043, -0.0031,  ..., -0.0127,  0.0014,  0.0070],\n",
       "         [-0.0058, -0.0081, -0.0062,  ..., -0.0054,  0.0130, -0.0095]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.mlp.down_proj.lora_A.weight': tensor([[-0.0080, -0.0026,  0.0011,  ...,  0.0005, -0.0076,  0.0040],\n",
       "         [ 0.0023,  0.0009,  0.0029,  ...,  0.0080,  0.0006, -0.0062],\n",
       "         [ 0.0005,  0.0009, -0.0011,  ..., -0.0017, -0.0021,  0.0006],\n",
       "         ...,\n",
       "         [ 0.0053,  0.0069, -0.0048,  ..., -0.0068,  0.0033,  0.0086],\n",
       "         [ 0.0033, -0.0045, -0.0047,  ..., -0.0043,  0.0094, -0.0033],\n",
       "         [ 0.0055, -0.0081, -0.0049,  ...,  0.0037, -0.0003,  0.0074]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.mlp.up_proj.lora_A.weight': tensor([[-0.0075, -0.0086, -0.0074,  ...,  0.0096,  0.0065, -0.0090],\n",
       "         [-0.0008,  0.0139, -0.0058,  ...,  0.0125,  0.0073,  0.0040],\n",
       "         [ 0.0049,  0.0074, -0.0083,  ..., -0.0140, -0.0113, -0.0046],\n",
       "         ...,\n",
       "         [ 0.0148,  0.0131,  0.0086,  ..., -0.0082,  0.0071,  0.0002],\n",
       "         [-0.0052, -0.0034,  0.0059,  ...,  0.0147, -0.0056,  0.0063],\n",
       "         [-0.0030, -0.0042, -0.0098,  ..., -0.0045, -0.0108,  0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.3.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight': tensor([[ 0.0053, -0.0108,  0.0056,  ...,  0.0028, -0.0010, -0.0083],\n",
       "         [-0.0046,  0.0065,  0.0090,  ...,  0.0018,  0.0060, -0.0067],\n",
       "         [-0.0091,  0.0105, -0.0008,  ...,  0.0104, -0.0112,  0.0029],\n",
       "         ...,\n",
       "         [-0.0086,  0.0155, -0.0140,  ...,  0.0114,  0.0107,  0.0108],\n",
       "         [-0.0123, -0.0119,  0.0108,  ...,  0.0134,  0.0117,  0.0116],\n",
       "         [ 0.0100,  0.0034, -0.0132,  ...,  0.0154,  0.0151,  0.0135]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.weight': tensor([[-0.0063, -0.0091,  0.0150,  ...,  0.0096,  0.0015,  0.0135],\n",
       "         [-0.0120, -0.0107, -0.0007,  ..., -0.0025, -0.0065,  0.0148],\n",
       "         [-0.0120, -0.0079, -0.0152,  ...,  0.0139,  0.0118, -0.0150],\n",
       "         ...,\n",
       "         [-0.0108, -0.0012, -0.0095,  ...,  0.0100,  0.0134, -0.0084],\n",
       "         [-0.0137, -0.0086,  0.0048,  ..., -0.0022, -0.0120, -0.0110],\n",
       "         [-0.0072, -0.0147,  0.0154,  ..., -0.0040, -0.0096, -0.0111]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight': tensor([[ 0.0069, -0.0125,  0.0089,  ..., -0.0127,  0.0032, -0.0060],\n",
       "         [ 0.0136, -0.0084, -0.0114,  ...,  0.0137,  0.0075,  0.0150],\n",
       "         [ 0.0038,  0.0005, -0.0005,  ...,  0.0096,  0.0110,  0.0122],\n",
       "         ...,\n",
       "         [ 0.0154, -0.0125, -0.0132,  ..., -0.0012,  0.0009, -0.0013],\n",
       "         [-0.0021, -0.0108, -0.0022,  ..., -0.0120, -0.0111, -0.0027],\n",
       "         [ 0.0112, -0.0073,  0.0074,  ...,  0.0142,  0.0117,  0.0139]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.weight': tensor([[-0.0136,  0.0132, -0.0144,  ..., -0.0001, -0.0094, -0.0078],\n",
       "         [-0.0002,  0.0092, -0.0108,  ...,  0.0098, -0.0131,  0.0145],\n",
       "         [-0.0129,  0.0005, -0.0049,  ...,  0.0136, -0.0058,  0.0117],\n",
       "         ...,\n",
       "         [-0.0110, -0.0123,  0.0017,  ..., -0.0040,  0.0146,  0.0040],\n",
       "         [-0.0110, -0.0082,  0.0021,  ..., -0.0009, -0.0059, -0.0095],\n",
       "         [ 0.0046, -0.0016, -0.0050,  ..., -0.0073,  0.0070,  0.0093]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.weight': tensor([[-0.0072,  0.0119, -0.0136,  ...,  0.0122,  0.0059,  0.0039],\n",
       "         [ 0.0036,  0.0124,  0.0060,  ...,  0.0001,  0.0072,  0.0129],\n",
       "         [-0.0102, -0.0050,  0.0133,  ...,  0.0136,  0.0121, -0.0133],\n",
       "         ...,\n",
       "         [-0.0141,  0.0103,  0.0005,  ..., -0.0070, -0.0134, -0.0093],\n",
       "         [-0.0042,  0.0066,  0.0117,  ...,  0.0071, -0.0004,  0.0118],\n",
       "         [ 0.0056, -0.0109, -0.0047,  ...,  0.0109, -0.0153, -0.0125]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.mlp.down_proj.lora_A.weight': tensor([[-0.0043,  0.0006, -0.0005,  ..., -0.0080, -0.0065,  0.0029],\n",
       "         [-0.0060, -0.0078, -0.0084,  ..., -0.0061, -0.0016, -0.0017],\n",
       "         [ 0.0081, -0.0025,  0.0066,  ..., -0.0073,  0.0082,  0.0035],\n",
       "         ...,\n",
       "         [-0.0008, -0.0066,  0.0059,  ...,  0.0062, -0.0092, -0.0013],\n",
       "         [ 0.0040, -0.0012, -0.0073,  ..., -0.0084,  0.0070, -0.0047],\n",
       "         [-0.0055, -0.0049, -0.0038,  ...,  0.0089,  0.0093,  0.0078]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.mlp.up_proj.lora_A.weight': tensor([[ 0.0132,  0.0094,  0.0146,  ..., -0.0124, -0.0016, -0.0010],\n",
       "         [-0.0066, -0.0036, -0.0137,  ..., -0.0028,  0.0095, -0.0087],\n",
       "         [-0.0034, -0.0099,  0.0110,  ...,  0.0151,  0.0076,  0.0027],\n",
       "         ...,\n",
       "         [ 0.0056,  0.0061, -0.0126,  ..., -0.0059,  0.0095,  0.0018],\n",
       "         [ 0.0072, -0.0142,  0.0145,  ..., -0.0029, -0.0044, -0.0096],\n",
       "         [-0.0105,  0.0022,  0.0052,  ...,  0.0020, -0.0003,  0.0108]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.4.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight': tensor([[ 0.0140, -0.0154, -0.0121,  ..., -0.0099,  0.0155,  0.0097],\n",
       "         [-0.0133, -0.0121,  0.0106,  ...,  0.0122,  0.0078,  0.0029],\n",
       "         [-0.0047,  0.0148,  0.0132,  ..., -0.0155,  0.0006, -0.0130],\n",
       "         ...,\n",
       "         [ 0.0055, -0.0118, -0.0014,  ..., -0.0145, -0.0102,  0.0145],\n",
       "         [ 0.0056, -0.0084,  0.0008,  ...,  0.0059, -0.0097, -0.0069],\n",
       "         [-0.0097, -0.0151,  0.0030,  ...,  0.0022,  0.0118,  0.0119]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.weight': tensor([[ 0.0020,  0.0041,  0.0015,  ..., -0.0010, -0.0117, -0.0128],\n",
       "         [ 0.0154, -0.0068, -0.0059,  ..., -0.0115,  0.0116,  0.0134],\n",
       "         [-0.0036, -0.0050,  0.0041,  ..., -0.0144, -0.0137,  0.0043],\n",
       "         ...,\n",
       "         [-0.0070,  0.0012, -0.0030,  ..., -0.0128, -0.0093,  0.0072],\n",
       "         [ 0.0144, -0.0143, -0.0099,  ...,  0.0040,  0.0049,  0.0056],\n",
       "         [-0.0062,  0.0092,  0.0059,  ..., -0.0044, -0.0029,  0.0008]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight': tensor([[ 5.6648e-03, -5.7259e-03, -8.4915e-03,  ..., -8.7202e-05,\n",
       "           8.4229e-03,  8.4996e-05],\n",
       "         [ 6.8045e-04, -3.1757e-03, -9.9277e-04,  ...,  4.3716e-03,\n",
       "          -1.3077e-02, -6.3095e-03],\n",
       "         [-7.9422e-03, -2.6436e-03,  7.4806e-03,  ..., -1.0529e-02,\n",
       "           1.5198e-02, -1.2871e-02],\n",
       "         ...,\n",
       "         [-1.2260e-02, -8.8806e-03,  6.9313e-03,  ...,  3.6526e-04,\n",
       "          -9.0790e-03,  7.9346e-03],\n",
       "         [-3.1662e-03, -1.2283e-02, -1.2962e-02,  ...,  8.3160e-03,\n",
       "          -9.2850e-03,  7.3280e-03],\n",
       "         [-8.1482e-03, -8.8501e-03,  1.4999e-02,  ...,  8.8272e-03,\n",
       "          -4.9706e-03,  1.1002e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.weight': tensor([[-0.0052, -0.0083, -0.0018,  ..., -0.0127, -0.0041, -0.0041],\n",
       "         [ 0.0144, -0.0143, -0.0080,  ..., -0.0059, -0.0026,  0.0116],\n",
       "         [-0.0041,  0.0044,  0.0064,  ..., -0.0063, -0.0143,  0.0039],\n",
       "         ...,\n",
       "         [ 0.0081, -0.0143,  0.0133,  ..., -0.0117, -0.0076,  0.0149],\n",
       "         [-0.0111,  0.0025, -0.0069,  ..., -0.0039,  0.0023,  0.0005],\n",
       "         [-0.0076,  0.0016,  0.0131,  ...,  0.0141,  0.0097,  0.0102]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.weight': tensor([[ 0.0079, -0.0068,  0.0034,  ...,  0.0069,  0.0134,  0.0082],\n",
       "         [-0.0110, -0.0113,  0.0094,  ..., -0.0033,  0.0141,  0.0005],\n",
       "         [ 0.0019, -0.0085, -0.0024,  ...,  0.0015,  0.0084,  0.0006],\n",
       "         ...,\n",
       "         [ 0.0063, -0.0083,  0.0021,  ..., -0.0028,  0.0022,  0.0134],\n",
       "         [ 0.0115,  0.0002,  0.0011,  ...,  0.0128,  0.0082, -0.0021],\n",
       "         [-0.0009,  0.0060, -0.0057,  ..., -0.0026, -0.0028,  0.0149]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.mlp.down_proj.lora_A.weight': tensor([[-0.0015,  0.0091, -0.0035,  ...,  0.0021,  0.0074, -0.0038],\n",
       "         [-0.0054,  0.0047,  0.0021,  ..., -0.0003,  0.0088,  0.0006],\n",
       "         [ 0.0090, -0.0083,  0.0026,  ..., -0.0071, -0.0095, -0.0080],\n",
       "         ...,\n",
       "         [ 0.0010, -0.0025,  0.0001,  ..., -0.0068,  0.0061,  0.0022],\n",
       "         [ 0.0032,  0.0031, -0.0076,  ..., -0.0088, -0.0032,  0.0005],\n",
       "         [ 0.0037,  0.0072,  0.0044,  ..., -0.0038,  0.0059, -0.0016]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.mlp.up_proj.lora_A.weight': tensor([[ 0.0087, -0.0082,  0.0059,  ...,  0.0044,  0.0037, -0.0134],\n",
       "         [ 0.0008,  0.0095, -0.0155,  ...,  0.0148, -0.0006, -0.0071],\n",
       "         [ 0.0019,  0.0118, -0.0046,  ...,  0.0068,  0.0153, -0.0112],\n",
       "         ...,\n",
       "         [ 0.0107, -0.0037,  0.0024,  ..., -0.0113,  0.0071,  0.0085],\n",
       "         [ 0.0092, -0.0062,  0.0022,  ...,  0.0087,  0.0021,  0.0079],\n",
       "         [-0.0091,  0.0005, -0.0086,  ...,  0.0026,  0.0080, -0.0093]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.5.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight': tensor([[ 0.0099,  0.0115,  0.0065,  ..., -0.0075,  0.0119,  0.0102],\n",
       "         [-0.0015, -0.0076, -0.0058,  ..., -0.0088,  0.0039,  0.0116],\n",
       "         [ 0.0141,  0.0152, -0.0154,  ..., -0.0006,  0.0114, -0.0141],\n",
       "         ...,\n",
       "         [-0.0079, -0.0082, -0.0003,  ...,  0.0127, -0.0124, -0.0155],\n",
       "         [-0.0064, -0.0062,  0.0133,  ..., -0.0096,  0.0095, -0.0056],\n",
       "         [-0.0118,  0.0100,  0.0141,  ..., -0.0072,  0.0084, -0.0007]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.weight': tensor([[ 0.0090, -0.0062, -0.0101,  ..., -0.0068, -0.0035,  0.0017],\n",
       "         [ 0.0088,  0.0002,  0.0150,  ..., -0.0082,  0.0089, -0.0105],\n",
       "         [ 0.0098, -0.0003,  0.0029,  ...,  0.0010,  0.0001, -0.0014],\n",
       "         ...,\n",
       "         [-0.0130,  0.0020,  0.0020,  ...,  0.0072,  0.0112,  0.0109],\n",
       "         [ 0.0006,  0.0072,  0.0073,  ..., -0.0026, -0.0024, -0.0084],\n",
       "         [-0.0035,  0.0142, -0.0089,  ..., -0.0129, -0.0038,  0.0143]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight': tensor([[ 0.0127,  0.0132,  0.0033,  ...,  0.0101, -0.0008, -0.0082],\n",
       "         [-0.0143, -0.0003,  0.0112,  ..., -0.0008,  0.0145,  0.0053],\n",
       "         [-0.0112,  0.0052, -0.0131,  ..., -0.0118,  0.0026,  0.0104],\n",
       "         ...,\n",
       "         [-0.0113, -0.0109, -0.0116,  ..., -0.0150, -0.0052,  0.0140],\n",
       "         [ 0.0024, -0.0129, -0.0115,  ..., -0.0112,  0.0094,  0.0036],\n",
       "         [ 0.0152, -0.0005, -0.0090,  ..., -0.0046,  0.0097, -0.0082]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.weight': tensor([[ 0.0076, -0.0009, -0.0031,  ...,  0.0003, -0.0119,  0.0042],\n",
       "         [ 0.0136,  0.0021, -0.0094,  ..., -0.0143,  0.0071,  0.0097],\n",
       "         [ 0.0121, -0.0068, -0.0084,  ...,  0.0009,  0.0065, -0.0004],\n",
       "         ...,\n",
       "         [-0.0102,  0.0010,  0.0094,  ...,  0.0106, -0.0145, -0.0062],\n",
       "         [-0.0030,  0.0077, -0.0090,  ..., -0.0054,  0.0016,  0.0153],\n",
       "         [-0.0071, -0.0088,  0.0079,  ...,  0.0132, -0.0026,  0.0131]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.weight': tensor([[-0.0028,  0.0101,  0.0086,  ..., -0.0088,  0.0039, -0.0101],\n",
       "         [-0.0112,  0.0132,  0.0058,  ..., -0.0017, -0.0063, -0.0129],\n",
       "         [ 0.0139,  0.0117,  0.0067,  ...,  0.0154,  0.0064, -0.0042],\n",
       "         ...,\n",
       "         [-0.0069, -0.0111, -0.0155,  ...,  0.0011, -0.0063, -0.0058],\n",
       "         [ 0.0115,  0.0090, -0.0087,  ...,  0.0084,  0.0120, -0.0069],\n",
       "         [-0.0120, -0.0142, -0.0072,  ...,  0.0156, -0.0135, -0.0014]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.mlp.down_proj.lora_A.weight': tensor([[ 0.0076,  0.0055,  0.0089,  ...,  0.0008, -0.0060, -0.0067],\n",
       "         [ 0.0092, -0.0086, -0.0001,  ...,  0.0063,  0.0082, -0.0048],\n",
       "         [ 0.0053, -0.0057,  0.0055,  ...,  0.0068, -0.0082,  0.0076],\n",
       "         ...,\n",
       "         [ 0.0039, -0.0082,  0.0062,  ..., -0.0039,  0.0032, -0.0041],\n",
       "         [ 0.0041, -0.0062, -0.0053,  ..., -0.0029,  0.0076, -0.0090],\n",
       "         [ 0.0059, -0.0090, -0.0089,  ...,  0.0094,  0.0006,  0.0067]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.mlp.up_proj.lora_A.weight': tensor([[-0.0022,  0.0089, -0.0141,  ..., -0.0073, -0.0080, -0.0048],\n",
       "         [-0.0156, -0.0024,  0.0105,  ...,  0.0144, -0.0046,  0.0003],\n",
       "         [-0.0141, -0.0003, -0.0129,  ..., -0.0056,  0.0084,  0.0038],\n",
       "         ...,\n",
       "         [-0.0100,  0.0046, -0.0110,  ...,  0.0064, -0.0085,  0.0006],\n",
       "         [-0.0036,  0.0072, -0.0047,  ...,  0.0055,  0.0152, -0.0112],\n",
       "         [ 0.0127,  0.0156,  0.0060,  ...,  0.0081,  0.0118, -0.0107]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.6.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight': tensor([[ 0.0131, -0.0104, -0.0128,  ...,  0.0156, -0.0018, -0.0071],\n",
       "         [-0.0102, -0.0030, -0.0106,  ...,  0.0038, -0.0097,  0.0030],\n",
       "         [-0.0119, -0.0013, -0.0116,  ..., -0.0059, -0.0012, -0.0037],\n",
       "         ...,\n",
       "         [ 0.0005, -0.0042, -0.0124,  ...,  0.0025,  0.0064,  0.0154],\n",
       "         [-0.0126, -0.0082, -0.0097,  ...,  0.0098,  0.0119, -0.0103],\n",
       "         [ 0.0100, -0.0101,  0.0059,  ..., -0.0124,  0.0076,  0.0010]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.weight': tensor([[ 0.0084,  0.0061,  0.0014,  ..., -0.0067, -0.0116, -0.0045],\n",
       "         [ 0.0103, -0.0131,  0.0046,  ...,  0.0059,  0.0003, -0.0005],\n",
       "         [ 0.0099, -0.0155, -0.0094,  ..., -0.0066,  0.0076, -0.0032],\n",
       "         ...,\n",
       "         [ 0.0146, -0.0016,  0.0056,  ...,  0.0148,  0.0044,  0.0079],\n",
       "         [ 0.0065, -0.0052,  0.0097,  ..., -0.0104,  0.0049, -0.0123],\n",
       "         [-0.0012, -0.0031,  0.0091,  ...,  0.0135, -0.0057, -0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight': tensor([[-0.0091, -0.0129, -0.0032,  ..., -0.0129,  0.0004, -0.0154],\n",
       "         [ 0.0074, -0.0020, -0.0053,  ..., -0.0128, -0.0095,  0.0153],\n",
       "         [ 0.0007, -0.0028, -0.0095,  ..., -0.0011,  0.0021, -0.0099],\n",
       "         ...,\n",
       "         [-0.0006,  0.0053,  0.0068,  ...,  0.0023, -0.0014, -0.0066],\n",
       "         [ 0.0141,  0.0151,  0.0153,  ...,  0.0092,  0.0073,  0.0026],\n",
       "         [ 0.0019,  0.0130,  0.0087,  ..., -0.0072, -0.0085,  0.0105]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.weight': tensor([[ 0.0110, -0.0115, -0.0086,  ...,  0.0025,  0.0152,  0.0140],\n",
       "         [ 0.0093, -0.0139,  0.0117,  ..., -0.0145,  0.0119,  0.0019],\n",
       "         [-0.0123,  0.0016,  0.0081,  ...,  0.0100, -0.0123, -0.0123],\n",
       "         ...,\n",
       "         [ 0.0083, -0.0147, -0.0001,  ...,  0.0084,  0.0113,  0.0049],\n",
       "         [ 0.0075,  0.0151, -0.0132,  ..., -0.0083, -0.0102, -0.0029],\n",
       "         [-0.0104,  0.0140, -0.0090,  ...,  0.0005,  0.0060,  0.0148]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.weight': tensor([[ 0.0057, -0.0058, -0.0083,  ...,  0.0018,  0.0076, -0.0030],\n",
       "         [-0.0141, -0.0126, -0.0049,  ...,  0.0127, -0.0077, -0.0155],\n",
       "         [-0.0103,  0.0002,  0.0148,  ..., -0.0150, -0.0089, -0.0103],\n",
       "         ...,\n",
       "         [-0.0136, -0.0061,  0.0144,  ...,  0.0120, -0.0154, -0.0052],\n",
       "         [-0.0047,  0.0003, -0.0091,  ...,  0.0090, -0.0120, -0.0021],\n",
       "         [-0.0044,  0.0009,  0.0124,  ...,  0.0088, -0.0150,  0.0112]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.mlp.down_proj.lora_A.weight': tensor([[-5.4512e-03, -7.6904e-03, -5.7335e-03,  ...,  8.4763e-03,\n",
       "          -3.5834e-04,  6.5384e-03],\n",
       "         [-7.1812e-04,  5.1460e-03,  8.5144e-03,  ...,  9.7561e-04,\n",
       "          -7.9651e-03,  7.5865e-04],\n",
       "         [-3.2711e-03,  1.2350e-03,  3.7632e-03,  ..., -3.8319e-03,\n",
       "           8.5297e-03, -3.3627e-03],\n",
       "         ...,\n",
       "         [-4.3564e-03, -6.0539e-03, -1.2648e-04,  ..., -2.5806e-03,\n",
       "          -4.6463e-03,  5.6534e-03],\n",
       "         [-5.2795e-03,  9.2850e-03, -9.2621e-03,  ...,  4.4465e-05,\n",
       "           8.1711e-03,  6.3820e-03],\n",
       "         [ 8.8043e-03,  5.4436e-03,  6.5880e-03,  ..., -8.6517e-03,\n",
       "          -7.4482e-04,  9.2010e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.mlp.up_proj.lora_A.weight': tensor([[-0.0154, -0.0116,  0.0043,  ..., -0.0020, -0.0033,  0.0146],\n",
       "         [-0.0049,  0.0148,  0.0098,  ...,  0.0126, -0.0026,  0.0064],\n",
       "         [-0.0128,  0.0012, -0.0079,  ...,  0.0014, -0.0055,  0.0013],\n",
       "         ...,\n",
       "         [-0.0053, -0.0137,  0.0132,  ..., -0.0054, -0.0081,  0.0058],\n",
       "         [ 0.0121,  0.0006, -0.0154,  ..., -0.0132, -0.0009, -0.0042],\n",
       "         [ 0.0004, -0.0014, -0.0155,  ...,  0.0041,  0.0128, -0.0031]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.7.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight': tensor([[-5.4588e-03, -9.1248e-03,  3.4847e-03,  ...,  6.8474e-03,\n",
       "           3.9101e-03, -5.9166e-03],\n",
       "         [-4.0779e-03, -5.0468e-03,  8.2703e-03,  ...,  1.2230e-02,\n",
       "           1.0666e-02,  1.1955e-02],\n",
       "         [ 6.0883e-03,  3.5000e-03,  8.6060e-03,  ..., -9.7580e-03,\n",
       "          -7.4577e-03, -7.3612e-05],\n",
       "         ...,\n",
       "         [-1.1482e-02, -9.4070e-03,  6.6071e-03,  ..., -3.6945e-03,\n",
       "          -1.3405e-02,  1.3870e-02],\n",
       "         [-2.6398e-03,  5.7077e-04,  4.1618e-03,  ..., -1.0063e-02,\n",
       "          -1.2169e-02, -5.4855e-03],\n",
       "         [-1.0437e-02, -2.3437e-04, -7.9651e-03,  ..., -1.2999e-03,\n",
       "           9.5596e-03, -1.4809e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.weight': tensor([[-6.5346e-03, -1.4053e-02, -1.1795e-02,  ...,  3.0022e-03,\n",
       "           8.0566e-03, -1.4000e-02],\n",
       "         [ 2.2488e-03, -7.4768e-04, -1.0849e-02,  ...,  6.6757e-04,\n",
       "          -9.8572e-03, -1.9875e-03],\n",
       "         [-7.9727e-03,  1.1467e-02, -1.4015e-02,  ...,  1.3714e-03,\n",
       "           7.5302e-03,  4.1542e-03],\n",
       "         ...,\n",
       "         [-6.5765e-03,  1.3634e-02, -7.9880e-03,  ...,  1.4122e-02,\n",
       "           7.0810e-05,  1.2245e-02],\n",
       "         [-1.2115e-02, -5.2490e-03, -1.5533e-02,  ...,  8.4152e-03,\n",
       "           9.0561e-03, -1.4009e-03],\n",
       "         [ 1.4137e-02,  4.6272e-03,  1.4046e-02,  ..., -2.0733e-03,\n",
       "          -1.2909e-02, -1.0574e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight': tensor([[ 0.0031, -0.0082, -0.0138,  ..., -0.0123, -0.0060, -0.0096],\n",
       "         [ 0.0118, -0.0053,  0.0047,  ...,  0.0052,  0.0045,  0.0021],\n",
       "         [-0.0031,  0.0086, -0.0086,  ..., -0.0135, -0.0074,  0.0147],\n",
       "         ...,\n",
       "         [ 0.0083,  0.0061, -0.0013,  ...,  0.0118, -0.0153, -0.0098],\n",
       "         [-0.0120, -0.0080, -0.0133,  ...,  0.0101, -0.0047, -0.0045],\n",
       "         [-0.0009,  0.0139, -0.0144,  ...,  0.0138,  0.0098, -0.0033]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.weight': tensor([[-0.0088,  0.0050,  0.0112,  ..., -0.0137,  0.0061,  0.0128],\n",
       "         [-0.0079, -0.0124,  0.0087,  ...,  0.0070, -0.0104, -0.0102],\n",
       "         [-0.0087, -0.0044, -0.0014,  ..., -0.0015, -0.0152,  0.0109],\n",
       "         ...,\n",
       "         [-0.0083, -0.0110, -0.0106,  ...,  0.0004, -0.0119, -0.0010],\n",
       "         [ 0.0141, -0.0119, -0.0069,  ...,  0.0038, -0.0092, -0.0091],\n",
       "         [ 0.0017,  0.0082, -0.0132,  ...,  0.0080,  0.0103, -0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.weight': tensor([[ 0.0020, -0.0049, -0.0073,  ..., -0.0139,  0.0126, -0.0142],\n",
       "         [ 0.0046,  0.0089, -0.0092,  ..., -0.0022, -0.0118,  0.0090],\n",
       "         [ 0.0133, -0.0134,  0.0071,  ..., -0.0036, -0.0142,  0.0143],\n",
       "         ...,\n",
       "         [-0.0104,  0.0065, -0.0079,  ...,  0.0113, -0.0051,  0.0008],\n",
       "         [ 0.0057, -0.0012, -0.0110,  ...,  0.0117,  0.0145,  0.0137],\n",
       "         [ 0.0077,  0.0154, -0.0005,  ..., -0.0040,  0.0027,  0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.mlp.down_proj.lora_A.weight': tensor([[ 0.0077, -0.0020,  0.0073,  ...,  0.0075, -0.0051, -0.0086],\n",
       "         [-0.0060,  0.0039,  0.0070,  ..., -0.0041,  0.0008, -0.0081],\n",
       "         [-0.0053,  0.0073,  0.0076,  ..., -0.0043, -0.0055,  0.0061],\n",
       "         ...,\n",
       "         [-0.0023,  0.0050,  0.0065,  ...,  0.0014,  0.0030, -0.0068],\n",
       "         [ 0.0033,  0.0021,  0.0069,  ...,  0.0095, -0.0032, -0.0063],\n",
       "         [ 0.0072,  0.0035, -0.0093,  ..., -0.0056, -0.0062,  0.0024]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.mlp.up_proj.lora_A.weight': tensor([[ 1.5278e-03,  5.9929e-03,  8.0338e-03,  ...,  1.5594e-02,\n",
       "           8.3084e-03, -2.0256e-03],\n",
       "         [ 1.5015e-02,  1.0841e-02, -1.1749e-02,  ...,  1.2856e-02,\n",
       "          -7.5722e-03, -1.1444e-02],\n",
       "         [-9.6970e-03, -5.5389e-03, -1.0796e-02,  ...,  5.1651e-03,\n",
       "           8.6486e-05, -2.9507e-03],\n",
       "         ...,\n",
       "         [-5.6000e-03,  5.5542e-03, -4.2076e-03,  ..., -1.0109e-02,\n",
       "           1.3542e-02,  1.3504e-02],\n",
       "         [ 2.9964e-03,  3.3894e-03, -7.1945e-03,  ...,  2.7294e-03,\n",
       "           7.2098e-03,  9.1629e-03],\n",
       "         [ 1.4481e-02, -4.3259e-03, -3.8662e-03,  ..., -7.6408e-03,\n",
       "           1.2121e-03, -1.5266e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.8.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight': tensor([[-1.2856e-02, -6.2294e-03,  1.7250e-04,  ...,  1.2596e-02,\n",
       "           2.8789e-05, -2.8782e-03],\n",
       "         [-1.0506e-02, -1.4633e-02,  6.5460e-03,  ..., -9.0027e-04,\n",
       "           1.3130e-02,  1.2306e-02],\n",
       "         [ 1.5610e-02, -4.5738e-03, -2.3136e-03,  ..., -5.5695e-03,\n",
       "           1.0803e-02, -1.5205e-02],\n",
       "         ...,\n",
       "         [ 1.4656e-02, -8.0948e-03, -1.0544e-02,  ..., -1.0347e-03,\n",
       "           4.1771e-03, -5.7678e-03],\n",
       "         [ 9.3765e-03, -7.3967e-03, -1.3344e-02,  ..., -1.4809e-02,\n",
       "          -8.6823e-03,  3.2101e-03],\n",
       "         [ 1.1053e-03,  4.2191e-03,  1.4145e-02,  ...,  1.0712e-02,\n",
       "          -3.9387e-04,  1.1024e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.weight': tensor([[ 0.0028,  0.0012,  0.0047,  ...,  0.0076,  0.0151, -0.0099],\n",
       "         [-0.0140, -0.0077, -0.0049,  ..., -0.0150, -0.0080,  0.0079],\n",
       "         [ 0.0012,  0.0036, -0.0030,  ...,  0.0084,  0.0139,  0.0013],\n",
       "         ...,\n",
       "         [ 0.0094, -0.0124, -0.0064,  ..., -0.0120,  0.0008,  0.0067],\n",
       "         [ 0.0136, -0.0004, -0.0054,  ..., -0.0016, -0.0097, -0.0102],\n",
       "         [-0.0037, -0.0071,  0.0069,  ..., -0.0108, -0.0080,  0.0155]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight': tensor([[-0.0050, -0.0083,  0.0095,  ...,  0.0063, -0.0130, -0.0025],\n",
       "         [ 0.0133, -0.0145, -0.0025,  ...,  0.0108,  0.0054, -0.0084],\n",
       "         [ 0.0063, -0.0079,  0.0110,  ..., -0.0073, -0.0009, -0.0008],\n",
       "         ...,\n",
       "         [-0.0009, -0.0043, -0.0040,  ..., -0.0156, -0.0102,  0.0046],\n",
       "         [ 0.0103,  0.0052, -0.0094,  ...,  0.0060,  0.0096, -0.0097],\n",
       "         [-0.0040, -0.0122, -0.0131,  ..., -0.0149, -0.0049,  0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.weight': tensor([[-0.0008, -0.0018,  0.0071,  ..., -0.0062,  0.0126,  0.0097],\n",
       "         [ 0.0008, -0.0139, -0.0135,  ...,  0.0007,  0.0064,  0.0064],\n",
       "         [ 0.0033, -0.0129, -0.0098,  ..., -0.0009, -0.0075,  0.0043],\n",
       "         ...,\n",
       "         [ 0.0050, -0.0083, -0.0041,  ...,  0.0023, -0.0036, -0.0058],\n",
       "         [-0.0019,  0.0154, -0.0068,  ..., -0.0039,  0.0124, -0.0145],\n",
       "         [-0.0074, -0.0093,  0.0082,  ...,  0.0026, -0.0068,  0.0020]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.weight': tensor([[-0.0076, -0.0073, -0.0047,  ...,  0.0016, -0.0139, -0.0002],\n",
       "         [-0.0134, -0.0086, -0.0148,  ..., -0.0035, -0.0095, -0.0066],\n",
       "         [-0.0100, -0.0011,  0.0134,  ..., -0.0128, -0.0068,  0.0146],\n",
       "         ...,\n",
       "         [ 0.0035, -0.0127, -0.0081,  ...,  0.0076,  0.0133, -0.0118],\n",
       "         [-0.0127,  0.0038,  0.0057,  ..., -0.0092, -0.0020,  0.0042],\n",
       "         [ 0.0043, -0.0088,  0.0105,  ...,  0.0079, -0.0126, -0.0058]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.mlp.down_proj.lora_A.weight': tensor([[ 0.0025, -0.0019, -0.0071,  ...,  0.0039, -0.0080,  0.0038],\n",
       "         [-0.0036,  0.0085, -0.0094,  ...,  0.0093, -0.0012,  0.0010],\n",
       "         [ 0.0039,  0.0004,  0.0077,  ..., -0.0003, -0.0018,  0.0027],\n",
       "         ...,\n",
       "         [-0.0052, -0.0016, -0.0072,  ...,  0.0055,  0.0016, -0.0036],\n",
       "         [ 0.0069, -0.0065,  0.0069,  ...,  0.0082,  0.0076, -0.0056],\n",
       "         [-0.0070,  0.0054,  0.0057,  ...,  0.0019,  0.0062, -0.0069]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.mlp.up_proj.lora_A.weight': tensor([[-0.0145,  0.0080, -0.0073,  ..., -0.0066,  0.0089, -0.0039],\n",
       "         [ 0.0098, -0.0049, -0.0074,  ...,  0.0020, -0.0054, -0.0089],\n",
       "         [-0.0059,  0.0095,  0.0117,  ...,  0.0114, -0.0012,  0.0087],\n",
       "         ...,\n",
       "         [ 0.0138,  0.0038,  0.0138,  ...,  0.0091, -0.0111,  0.0106],\n",
       "         [ 0.0128,  0.0097,  0.0080,  ..., -0.0049, -0.0124, -0.0071],\n",
       "         [ 0.0067,  0.0015,  0.0144,  ..., -0.0066, -0.0108,  0.0033]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.9.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight': tensor([[-0.0047,  0.0045, -0.0097,  ...,  0.0137,  0.0124,  0.0085],\n",
       "         [-0.0016, -0.0151,  0.0054,  ...,  0.0111, -0.0143, -0.0059],\n",
       "         [-0.0013, -0.0020,  0.0114,  ..., -0.0091,  0.0053,  0.0156],\n",
       "         ...,\n",
       "         [ 0.0053, -0.0132,  0.0080,  ..., -0.0006, -0.0146,  0.0103],\n",
       "         [-0.0076, -0.0022, -0.0087,  ..., -0.0119, -0.0051,  0.0038],\n",
       "         [-0.0134,  0.0124, -0.0066,  ..., -0.0126, -0.0071,  0.0008]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.weight': tensor([[ 0.0145, -0.0075, -0.0096,  ..., -0.0022,  0.0074, -0.0024],\n",
       "         [ 0.0011,  0.0149, -0.0033,  ...,  0.0071,  0.0150, -0.0119],\n",
       "         [ 0.0012, -0.0027, -0.0089,  ..., -0.0040, -0.0104, -0.0129],\n",
       "         ...,\n",
       "         [ 0.0026,  0.0038,  0.0015,  ..., -0.0131,  0.0056, -0.0151],\n",
       "         [ 0.0043,  0.0101, -0.0129,  ..., -0.0156, -0.0087, -0.0078],\n",
       "         [-0.0037,  0.0010, -0.0026,  ...,  0.0139,  0.0002,  0.0060]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight': tensor([[ 0.0046, -0.0110,  0.0126,  ..., -0.0063, -0.0107, -0.0108],\n",
       "         [-0.0099,  0.0099,  0.0149,  ...,  0.0096,  0.0142, -0.0154],\n",
       "         [ 0.0127, -0.0069, -0.0047,  ..., -0.0136,  0.0004,  0.0123],\n",
       "         ...,\n",
       "         [ 0.0061,  0.0153,  0.0084,  ..., -0.0088, -0.0110, -0.0014],\n",
       "         [-0.0146, -0.0007,  0.0070,  ...,  0.0058, -0.0021,  0.0089],\n",
       "         [-0.0123, -0.0131,  0.0026,  ...,  0.0035, -0.0148,  0.0145]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.weight': tensor([[-0.0036,  0.0048,  0.0056,  ..., -0.0068,  0.0102, -0.0069],\n",
       "         [-0.0053,  0.0058, -0.0070,  ..., -0.0009, -0.0123, -0.0101],\n",
       "         [ 0.0155,  0.0057,  0.0065,  ..., -0.0138, -0.0128, -0.0138],\n",
       "         ...,\n",
       "         [ 0.0093,  0.0137, -0.0025,  ..., -0.0156,  0.0060,  0.0069],\n",
       "         [-0.0128,  0.0119,  0.0015,  ..., -0.0050, -0.0104,  0.0041],\n",
       "         [ 0.0027, -0.0029,  0.0003,  ..., -0.0048,  0.0035, -0.0046]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.weight': tensor([[ 0.0138, -0.0061,  0.0111,  ...,  0.0111, -0.0073, -0.0077],\n",
       "         [ 0.0062,  0.0042,  0.0039,  ...,  0.0050, -0.0153, -0.0126],\n",
       "         [-0.0110, -0.0030, -0.0035,  ...,  0.0085, -0.0059,  0.0010],\n",
       "         ...,\n",
       "         [ 0.0064,  0.0103, -0.0137,  ...,  0.0151, -0.0135, -0.0024],\n",
       "         [ 0.0060, -0.0106, -0.0022,  ...,  0.0112,  0.0078,  0.0102],\n",
       "         [ 0.0138,  0.0071, -0.0024,  ...,  0.0029,  0.0084, -0.0067]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.mlp.down_proj.lora_A.weight': tensor([[ 0.0029,  0.0056, -0.0024,  ..., -0.0006, -0.0021,  0.0060],\n",
       "         [ 0.0059, -0.0022,  0.0003,  ..., -0.0080, -0.0093,  0.0052],\n",
       "         [ 0.0023, -0.0023, -0.0088,  ..., -0.0062, -0.0015,  0.0027],\n",
       "         ...,\n",
       "         [-0.0053, -0.0091,  0.0008,  ...,  0.0091,  0.0022,  0.0084],\n",
       "         [-0.0024,  0.0074,  0.0062,  ...,  0.0031,  0.0069,  0.0006],\n",
       "         [-0.0058, -0.0001, -0.0007,  ...,  0.0026, -0.0030,  0.0067]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.mlp.up_proj.lora_A.weight': tensor([[ 0.0124,  0.0080,  0.0147,  ...,  0.0137,  0.0100, -0.0134],\n",
       "         [ 0.0148, -0.0003,  0.0080,  ...,  0.0129,  0.0134, -0.0127],\n",
       "         [ 0.0083, -0.0019,  0.0029,  ...,  0.0084, -0.0052,  0.0137],\n",
       "         ...,\n",
       "         [ 0.0009, -0.0086, -0.0138,  ..., -0.0117,  0.0121,  0.0072],\n",
       "         [-0.0149, -0.0086, -0.0138,  ..., -0.0150,  0.0134,  0.0102],\n",
       "         [ 0.0151, -0.0068,  0.0053,  ...,  0.0153, -0.0085,  0.0015]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.10.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight': tensor([[ 0.0064, -0.0118, -0.0096,  ..., -0.0103, -0.0128, -0.0100],\n",
       "         [ 0.0145, -0.0044,  0.0043,  ...,  0.0102, -0.0061, -0.0028],\n",
       "         [-0.0068, -0.0018,  0.0082,  ...,  0.0076,  0.0107,  0.0025],\n",
       "         ...,\n",
       "         [ 0.0008, -0.0153,  0.0051,  ...,  0.0019, -0.0103,  0.0125],\n",
       "         [ 0.0037, -0.0022,  0.0003,  ..., -0.0030,  0.0145, -0.0046],\n",
       "         [-0.0143, -0.0040,  0.0035,  ..., -0.0109,  0.0011, -0.0034]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.weight': tensor([[-0.0029, -0.0017,  0.0034,  ...,  0.0074, -0.0064, -0.0071],\n",
       "         [-0.0009,  0.0065, -0.0015,  ..., -0.0047, -0.0072, -0.0080],\n",
       "         [-0.0019,  0.0111,  0.0029,  ...,  0.0036,  0.0148, -0.0127],\n",
       "         ...,\n",
       "         [ 0.0032, -0.0026,  0.0126,  ...,  0.0106,  0.0075, -0.0124],\n",
       "         [-0.0060, -0.0014, -0.0090,  ...,  0.0075, -0.0097, -0.0143],\n",
       "         [ 0.0058, -0.0137, -0.0113,  ..., -0.0007, -0.0121, -0.0004]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight': tensor([[-0.0106,  0.0076, -0.0121,  ...,  0.0122, -0.0088,  0.0070],\n",
       "         [ 0.0011, -0.0121,  0.0099,  ...,  0.0108,  0.0095, -0.0096],\n",
       "         [ 0.0050,  0.0057,  0.0119,  ..., -0.0121,  0.0048,  0.0017],\n",
       "         ...,\n",
       "         [-0.0003,  0.0078, -0.0127,  ...,  0.0152, -0.0119, -0.0112],\n",
       "         [ 0.0043, -0.0153,  0.0077,  ..., -0.0077, -0.0125,  0.0034],\n",
       "         [ 0.0134,  0.0027,  0.0149,  ..., -0.0028, -0.0114, -0.0012]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.weight': tensor([[-0.0032,  0.0084,  0.0082,  ...,  0.0043, -0.0021, -0.0082],\n",
       "         [-0.0062, -0.0070,  0.0145,  ...,  0.0017,  0.0088, -0.0103],\n",
       "         [ 0.0149, -0.0105, -0.0028,  ..., -0.0074, -0.0063,  0.0025],\n",
       "         ...,\n",
       "         [ 0.0056,  0.0062, -0.0051,  ..., -0.0119,  0.0137,  0.0084],\n",
       "         [-0.0099, -0.0082,  0.0009,  ..., -0.0139, -0.0036,  0.0058],\n",
       "         [ 0.0090,  0.0143,  0.0126,  ..., -0.0141, -0.0062, -0.0034]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.weight': tensor([[-0.0053, -0.0005,  0.0083,  ..., -0.0028,  0.0088,  0.0117],\n",
       "         [ 0.0135, -0.0086, -0.0149,  ...,  0.0058,  0.0135,  0.0060],\n",
       "         [-0.0029,  0.0085,  0.0082,  ...,  0.0047, -0.0134,  0.0048],\n",
       "         ...,\n",
       "         [-0.0055, -0.0132, -0.0026,  ..., -0.0128, -0.0073, -0.0021],\n",
       "         [-0.0106,  0.0091, -0.0016,  ...,  0.0129,  0.0097,  0.0064],\n",
       "         [ 0.0078, -0.0108, -0.0026,  ..., -0.0146, -0.0007, -0.0125]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.mlp.down_proj.lora_A.weight': tensor([[ 6.9847e-03, -7.2327e-03,  3.5172e-03,  ..., -8.3008e-03,\n",
       "           7.9498e-03, -7.5722e-03],\n",
       "         [-7.6485e-03, -5.4092e-03, -9.0218e-04,  ..., -2.7142e-03,\n",
       "          -6.5565e-07, -3.3474e-03],\n",
       "         [ 4.2267e-03, -8.0185e-03,  7.9250e-04,  ...,  1.6260e-03,\n",
       "           9.4376e-03,  4.5547e-03],\n",
       "         ...,\n",
       "         [-5.1212e-04, -5.4855e-03, -8.7967e-03,  ...,  9.2087e-03,\n",
       "          -3.0632e-03,  2.0771e-03],\n",
       "         [-1.5354e-03,  7.9117e-03,  4.9324e-03,  ..., -2.1172e-03,\n",
       "          -4.0703e-03, -5.8937e-04],\n",
       "         [-2.6665e-03, -2.9125e-03,  9.3918e-03,  ...,  7.2136e-03,\n",
       "          -2.2621e-03,  2.8896e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.mlp.up_proj.lora_A.weight': tensor([[-0.0156,  0.0139, -0.0098,  ..., -0.0052,  0.0033,  0.0053],\n",
       "         [-0.0075, -0.0137, -0.0075,  ..., -0.0005,  0.0045, -0.0021],\n",
       "         [ 0.0078,  0.0117,  0.0004,  ..., -0.0022, -0.0009, -0.0132],\n",
       "         ...,\n",
       "         [ 0.0109, -0.0075,  0.0059,  ...,  0.0026,  0.0069, -0.0126],\n",
       "         [ 0.0107,  0.0054, -0.0142,  ...,  0.0033,  0.0068, -0.0065],\n",
       "         [ 0.0121,  0.0002, -0.0006,  ...,  0.0096, -0.0003, -0.0053]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.11.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight': tensor([[-0.0084,  0.0129,  0.0137,  ..., -0.0018, -0.0059, -0.0035],\n",
       "         [ 0.0091, -0.0089, -0.0085,  ...,  0.0059, -0.0029,  0.0023],\n",
       "         [-0.0002,  0.0046, -0.0117,  ...,  0.0003,  0.0091, -0.0020],\n",
       "         ...,\n",
       "         [-0.0061,  0.0005, -0.0141,  ...,  0.0123,  0.0107,  0.0115],\n",
       "         [ 0.0136, -0.0125, -0.0136,  ...,  0.0022,  0.0060,  0.0059],\n",
       "         [ 0.0029,  0.0027,  0.0061,  ...,  0.0131,  0.0093, -0.0146]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.weight': tensor([[ 0.0066,  0.0125,  0.0012,  ...,  0.0145, -0.0145, -0.0155],\n",
       "         [ 0.0128, -0.0104, -0.0104,  ..., -0.0038, -0.0116,  0.0147],\n",
       "         [ 0.0125, -0.0036,  0.0055,  ...,  0.0088, -0.0130, -0.0145],\n",
       "         ...,\n",
       "         [-0.0091,  0.0057, -0.0067,  ...,  0.0133, -0.0024, -0.0135],\n",
       "         [ 0.0022, -0.0142, -0.0078,  ..., -0.0045, -0.0107,  0.0126],\n",
       "         [ 0.0148,  0.0025,  0.0072,  ..., -0.0096,  0.0086, -0.0077]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight': tensor([[-0.0108, -0.0093, -0.0139,  ...,  0.0024, -0.0092, -0.0051],\n",
       "         [ 0.0040,  0.0062, -0.0020,  ..., -0.0028,  0.0084,  0.0079],\n",
       "         [-0.0025, -0.0140, -0.0119,  ...,  0.0007, -0.0033, -0.0015],\n",
       "         ...,\n",
       "         [ 0.0011, -0.0076,  0.0061,  ...,  0.0129, -0.0107,  0.0071],\n",
       "         [ 0.0131, -0.0135, -0.0079,  ..., -0.0013, -0.0155,  0.0067],\n",
       "         [-0.0056, -0.0154,  0.0066,  ...,  0.0062,  0.0060, -0.0022]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.weight': tensor([[-0.0125, -0.0082,  0.0138,  ...,  0.0047,  0.0068, -0.0138],\n",
       "         [-0.0058, -0.0070,  0.0002,  ...,  0.0133,  0.0120,  0.0089],\n",
       "         [ 0.0154,  0.0097, -0.0087,  ...,  0.0118, -0.0092, -0.0100],\n",
       "         ...,\n",
       "         [ 0.0030,  0.0126,  0.0113,  ...,  0.0086, -0.0132,  0.0020],\n",
       "         [-0.0135,  0.0149, -0.0052,  ..., -0.0149,  0.0129,  0.0139],\n",
       "         [-0.0149,  0.0135,  0.0054,  ...,  0.0079, -0.0027, -0.0046]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.weight': tensor([[ 2.4223e-03, -1.2550e-02,  1.2955e-02,  ...,  1.2627e-02,\n",
       "           1.1501e-03, -7.7486e-05],\n",
       "         [-1.3100e-02,  1.1345e-02, -9.0790e-03,  ...,  1.3802e-02,\n",
       "          -8.5678e-03, -6.1722e-03],\n",
       "         [ 1.1292e-02, -4.7226e-03, -8.6904e-05,  ..., -9.3918e-03,\n",
       "          -1.5259e-02,  1.7614e-03],\n",
       "         ...,\n",
       "         [ 4.1809e-03,  6.0654e-03, -1.4397e-02,  ...,  1.1978e-02,\n",
       "          -9.8228e-04,  9.3307e-03],\n",
       "         [ 4.1389e-03,  5.3978e-03,  2.8839e-03,  ..., -6.9618e-03,\n",
       "           4.5128e-03,  1.5083e-02],\n",
       "         [ 1.0214e-03,  3.1319e-03,  6.7825e-03,  ...,  4.2152e-03,\n",
       "          -1.1810e-02,  7.9956e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.mlp.down_proj.lora_A.weight': tensor([[-1.3523e-03,  5.5809e-03,  7.2060e-03,  ..., -7.3385e-04,\n",
       "           7.0496e-03, -6.2904e-03],\n",
       "         [ 3.8490e-03, -9.4757e-03,  3.3722e-03,  ..., -8.1635e-03,\n",
       "          -1.8418e-05,  2.9469e-03],\n",
       "         [-2.4738e-03,  4.4098e-03,  2.7351e-03,  ...,  4.7607e-03,\n",
       "          -1.9798e-03, -7.0155e-05],\n",
       "         ...,\n",
       "         [ 7.3090e-03,  8.4991e-03, -5.2738e-04,  ..., -9.3231e-03,\n",
       "          -8.7662e-03,  1.5125e-03],\n",
       "         [ 1.3552e-03,  8.3160e-03, -4.2992e-03,  ...,  9.4604e-03,\n",
       "          -2.4128e-03,  7.7858e-03],\n",
       "         [-8.2350e-04,  8.4381e-03, -2.7523e-03,  ..., -4.3221e-03,\n",
       "          -1.1425e-03, -5.9700e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.mlp.up_proj.lora_A.weight': tensor([[ 0.0053,  0.0004,  0.0104,  ..., -0.0112,  0.0079,  0.0128],\n",
       "         [-0.0141, -0.0075,  0.0145,  ..., -0.0012,  0.0097,  0.0019],\n",
       "         [-0.0108,  0.0030,  0.0127,  ...,  0.0148, -0.0114,  0.0013],\n",
       "         ...,\n",
       "         [ 0.0017,  0.0080, -0.0066,  ...,  0.0042, -0.0089, -0.0024],\n",
       "         [ 0.0071, -0.0068, -0.0077,  ...,  0.0100, -0.0072, -0.0081],\n",
       "         [-0.0053,  0.0063,  0.0120,  ..., -0.0137,  0.0130,  0.0140]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.12.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight': tensor([[ 0.0059,  0.0132, -0.0086,  ...,  0.0086,  0.0094, -0.0011],\n",
       "         [-0.0068,  0.0135, -0.0099,  ...,  0.0036, -0.0063, -0.0044],\n",
       "         [ 0.0062,  0.0129, -0.0122,  ...,  0.0025,  0.0040, -0.0135],\n",
       "         ...,\n",
       "         [ 0.0035, -0.0005,  0.0071,  ..., -0.0141,  0.0111, -0.0123],\n",
       "         [ 0.0026, -0.0010,  0.0136,  ..., -0.0152,  0.0004,  0.0006],\n",
       "         [ 0.0013, -0.0152,  0.0045,  ..., -0.0137, -0.0069,  0.0039]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.weight': tensor([[ 0.0149,  0.0015,  0.0059,  ...,  0.0082, -0.0055,  0.0025],\n",
       "         [-0.0107,  0.0053,  0.0069,  ..., -0.0030,  0.0042,  0.0116],\n",
       "         [-0.0062,  0.0042, -0.0096,  ..., -0.0103,  0.0024, -0.0024],\n",
       "         ...,\n",
       "         [ 0.0088, -0.0050, -0.0108,  ...,  0.0153,  0.0031,  0.0081],\n",
       "         [-0.0114, -0.0138,  0.0027,  ..., -0.0135, -0.0016,  0.0035],\n",
       "         [-0.0151, -0.0070, -0.0044,  ...,  0.0048, -0.0076,  0.0100]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight': tensor([[-0.0093, -0.0009,  0.0139,  ...,  0.0087,  0.0144, -0.0116],\n",
       "         [ 0.0082, -0.0116, -0.0102,  ..., -0.0048,  0.0054, -0.0131],\n",
       "         [ 0.0115, -0.0004, -0.0121,  ..., -0.0147,  0.0102, -0.0087],\n",
       "         ...,\n",
       "         [-0.0096,  0.0076, -0.0121,  ...,  0.0009,  0.0114,  0.0013],\n",
       "         [-0.0017,  0.0140, -0.0123,  ..., -0.0056,  0.0006,  0.0144],\n",
       "         [ 0.0139,  0.0028,  0.0066,  ...,  0.0138, -0.0131,  0.0016]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.weight': tensor([[ 0.0143, -0.0071, -0.0024,  ..., -0.0145, -0.0052,  0.0033],\n",
       "         [ 0.0137, -0.0125,  0.0113,  ...,  0.0079, -0.0124,  0.0132],\n",
       "         [ 0.0010,  0.0016, -0.0086,  ..., -0.0031,  0.0113, -0.0059],\n",
       "         ...,\n",
       "         [ 0.0067,  0.0022,  0.0089,  ..., -0.0059,  0.0067,  0.0067],\n",
       "         [-0.0089,  0.0120,  0.0147,  ..., -0.0052, -0.0021,  0.0003],\n",
       "         [ 0.0056, -0.0073, -0.0019,  ...,  0.0100,  0.0083, -0.0091]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.weight': tensor([[ 0.0117,  0.0129,  0.0042,  ..., -0.0121,  0.0055, -0.0119],\n",
       "         [-0.0091, -0.0070, -0.0154,  ..., -0.0144, -0.0013, -0.0095],\n",
       "         [ 0.0103,  0.0152,  0.0004,  ..., -0.0133,  0.0013, -0.0134],\n",
       "         ...,\n",
       "         [-0.0069,  0.0088,  0.0141,  ...,  0.0143, -0.0086, -0.0007],\n",
       "         [-0.0047,  0.0149,  0.0080,  ..., -0.0031, -0.0122,  0.0118],\n",
       "         [ 0.0121,  0.0015, -0.0075,  ...,  0.0086, -0.0138, -0.0098]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.mlp.down_proj.lora_A.weight': tensor([[-4.2343e-03, -3.4885e-03, -8.0490e-03,  ..., -4.5815e-03,\n",
       "          -2.7790e-03,  9.3842e-03],\n",
       "         [-1.2994e-05,  8.5602e-03,  5.5742e-04,  ...,  2.1992e-03,\n",
       "          -5.8060e-03,  5.2719e-03],\n",
       "         [-6.6032e-03,  6.8207e-03,  7.8354e-03,  ..., -8.7662e-03,\n",
       "           1.3266e-03, -1.8823e-04],\n",
       "         ...,\n",
       "         [ 2.2449e-03, -6.2943e-03, -1.5669e-03,  ...,  7.6942e-03,\n",
       "          -6.2103e-03,  2.8954e-03],\n",
       "         [ 3.0060e-03, -2.2926e-03,  6.4433e-05,  ...,  1.7204e-03,\n",
       "          -1.0576e-03,  7.3891e-03],\n",
       "         [ 4.7913e-03,  6.4888e-03,  8.4610e-03,  ..., -2.8324e-03,\n",
       "           4.7731e-04,  7.7896e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.mlp.up_proj.lora_A.weight': tensor([[-0.0031,  0.0009,  0.0014,  ..., -0.0150, -0.0110,  0.0106],\n",
       "         [-0.0028,  0.0154,  0.0066,  ..., -0.0155,  0.0089,  0.0053],\n",
       "         [-0.0019,  0.0090,  0.0121,  ...,  0.0090, -0.0126,  0.0006],\n",
       "         ...,\n",
       "         [ 0.0006,  0.0076, -0.0111,  ..., -0.0142, -0.0068,  0.0011],\n",
       "         [ 0.0141,  0.0050, -0.0012,  ..., -0.0076,  0.0102,  0.0038],\n",
       "         [-0.0122,  0.0024, -0.0131,  ..., -0.0050, -0.0124,  0.0153]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.13.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight': tensor([[ 0.0054, -0.0146,  0.0062,  ...,  0.0025,  0.0090,  0.0078],\n",
       "         [ 0.0019,  0.0055, -0.0122,  ..., -0.0070, -0.0122, -0.0109],\n",
       "         [ 0.0148, -0.0127,  0.0131,  ...,  0.0099, -0.0025, -0.0092],\n",
       "         ...,\n",
       "         [ 0.0063, -0.0051, -0.0052,  ...,  0.0127,  0.0152,  0.0040],\n",
       "         [-0.0101,  0.0085, -0.0024,  ...,  0.0004,  0.0039, -0.0145],\n",
       "         [-0.0139,  0.0110,  0.0058,  ...,  0.0152,  0.0071, -0.0059]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.weight': tensor([[-0.0147, -0.0036,  0.0047,  ..., -0.0053, -0.0032,  0.0136],\n",
       "         [-0.0024, -0.0093,  0.0143,  ..., -0.0151,  0.0081,  0.0062],\n",
       "         [-0.0053,  0.0024,  0.0045,  ..., -0.0022, -0.0034,  0.0115],\n",
       "         ...,\n",
       "         [-0.0054,  0.0017,  0.0043,  ...,  0.0028, -0.0068, -0.0044],\n",
       "         [-0.0063, -0.0033, -0.0045,  ..., -0.0123,  0.0103,  0.0017],\n",
       "         [-0.0008, -0.0054, -0.0061,  ..., -0.0134,  0.0024,  0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight': tensor([[-0.0113,  0.0128, -0.0105,  ...,  0.0129, -0.0089, -0.0075],\n",
       "         [ 0.0022,  0.0073,  0.0065,  ..., -0.0104,  0.0012, -0.0017],\n",
       "         [ 0.0133, -0.0060, -0.0016,  ...,  0.0076, -0.0017, -0.0146],\n",
       "         ...,\n",
       "         [ 0.0046,  0.0089, -0.0003,  ...,  0.0064,  0.0020, -0.0147],\n",
       "         [-0.0027, -0.0086,  0.0019,  ..., -0.0003, -0.0128, -0.0085],\n",
       "         [-0.0055,  0.0104,  0.0040,  ..., -0.0026, -0.0111,  0.0156]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.weight': tensor([[ 1.3107e-02, -1.5602e-02,  6.2561e-03,  ..., -5.6267e-03,\n",
       "          -9.5901e-03,  4.1504e-03],\n",
       "         [-7.6561e-03, -1.5106e-02, -2.2182e-03,  ..., -1.2894e-02,\n",
       "           6.5575e-03, -7.2403e-03],\n",
       "         [ 1.2445e-03,  9.3307e-03,  7.9880e-03,  ...,  8.7738e-03,\n",
       "           2.3899e-03,  9.8419e-04],\n",
       "         ...,\n",
       "         [ 1.4057e-03,  5.6229e-03,  7.6447e-03,  ..., -2.0447e-03,\n",
       "           8.0185e-03, -7.3738e-03],\n",
       "         [ 6.2609e-04, -1.5129e-02, -3.2597e-03,  ...,  1.0811e-02,\n",
       "          -1.5469e-03,  1.3802e-02],\n",
       "         [-1.4099e-02,  7.5378e-03,  1.2520e-02,  ...,  8.6832e-04,\n",
       "          -1.4595e-02, -5.4002e-05]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.weight': tensor([[ 0.0055, -0.0126, -0.0120,  ...,  0.0133, -0.0121,  0.0075],\n",
       "         [-0.0026, -0.0154, -0.0101,  ...,  0.0056,  0.0102, -0.0114],\n",
       "         [-0.0007, -0.0013, -0.0038,  ..., -0.0102,  0.0142, -0.0044],\n",
       "         ...,\n",
       "         [-0.0132, -0.0121, -0.0110,  ...,  0.0127, -0.0051,  0.0154],\n",
       "         [-0.0091,  0.0066,  0.0101,  ..., -0.0044, -0.0016, -0.0130],\n",
       "         [-0.0080,  0.0156,  0.0038,  ...,  0.0105, -0.0055,  0.0040]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.mlp.down_proj.lora_A.weight': tensor([[ 0.0066,  0.0005,  0.0086,  ...,  0.0036, -0.0036,  0.0044],\n",
       "         [-0.0095,  0.0008,  0.0038,  ..., -0.0056, -0.0050,  0.0062],\n",
       "         [-0.0008,  0.0029,  0.0085,  ...,  0.0032,  0.0027, -0.0017],\n",
       "         ...,\n",
       "         [-0.0051,  0.0033, -0.0048,  ..., -0.0027,  0.0069,  0.0047],\n",
       "         [ 0.0073, -0.0078, -0.0008,  ..., -0.0022, -0.0034,  0.0063],\n",
       "         [ 0.0047,  0.0081,  0.0006,  ..., -0.0083, -0.0013, -0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.mlp.up_proj.lora_A.weight': tensor([[-0.0066, -0.0031, -0.0126,  ...,  0.0098, -0.0005,  0.0018],\n",
       "         [-0.0020,  0.0126, -0.0098,  ..., -0.0100,  0.0132,  0.0049],\n",
       "         [ 0.0110,  0.0127, -0.0115,  ..., -0.0109, -0.0130, -0.0036],\n",
       "         ...,\n",
       "         [-0.0154,  0.0136, -0.0028,  ..., -0.0042, -0.0018,  0.0155],\n",
       "         [ 0.0027,  0.0141, -0.0046,  ..., -0.0078, -0.0013,  0.0141],\n",
       "         [ 0.0074, -0.0122, -0.0021,  ..., -0.0156, -0.0146, -0.0025]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.14.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight': tensor([[ 0.0053,  0.0025,  0.0048,  ...,  0.0062,  0.0065, -0.0026],\n",
       "         [-0.0074, -0.0057, -0.0153,  ..., -0.0086, -0.0156,  0.0113],\n",
       "         [ 0.0014,  0.0076,  0.0011,  ..., -0.0065, -0.0005,  0.0049],\n",
       "         ...,\n",
       "         [-0.0141, -0.0088, -0.0141,  ..., -0.0025, -0.0114, -0.0012],\n",
       "         [ 0.0116, -0.0090, -0.0081,  ...,  0.0152,  0.0066, -0.0091],\n",
       "         [-0.0088,  0.0009,  0.0026,  ..., -0.0138, -0.0116,  0.0062]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.weight': tensor([[ 0.0129,  0.0148,  0.0051,  ..., -0.0135, -0.0042,  0.0123],\n",
       "         [ 0.0034, -0.0022, -0.0002,  ...,  0.0041,  0.0042,  0.0016],\n",
       "         [ 0.0109, -0.0019, -0.0035,  ..., -0.0096, -0.0107,  0.0133],\n",
       "         ...,\n",
       "         [ 0.0115, -0.0073,  0.0140,  ...,  0.0053, -0.0085,  0.0142],\n",
       "         [ 0.0091,  0.0128, -0.0039,  ..., -0.0080, -0.0100, -0.0144],\n",
       "         [-0.0018, -0.0032,  0.0108,  ..., -0.0077,  0.0006, -0.0104]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight': tensor([[ 0.0019, -0.0079, -0.0068,  ...,  0.0121,  0.0050, -0.0132],\n",
       "         [-0.0064,  0.0151, -0.0113,  ..., -0.0022, -0.0011, -0.0035],\n",
       "         [ 0.0044, -0.0136, -0.0113,  ...,  0.0136, -0.0119,  0.0145],\n",
       "         ...,\n",
       "         [ 0.0056,  0.0142, -0.0019,  ...,  0.0090, -0.0097, -0.0032],\n",
       "         [-0.0047,  0.0032, -0.0072,  ..., -0.0116,  0.0148, -0.0039],\n",
       "         [ 0.0032,  0.0125,  0.0110,  ..., -0.0074,  0.0148, -0.0030]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.weight': tensor([[ 0.0088,  0.0098,  0.0075,  ...,  0.0019, -0.0133,  0.0032],\n",
       "         [ 0.0028,  0.0087, -0.0056,  ...,  0.0141,  0.0006,  0.0097],\n",
       "         [-0.0016,  0.0087,  0.0135,  ..., -0.0151, -0.0083, -0.0117],\n",
       "         ...,\n",
       "         [-0.0134,  0.0015,  0.0075,  ...,  0.0042,  0.0039,  0.0007],\n",
       "         [-0.0065,  0.0087,  0.0020,  ..., -0.0054, -0.0043, -0.0145],\n",
       "         [ 0.0137,  0.0099, -0.0134,  ...,  0.0098,  0.0046,  0.0078]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.weight': tensor([[ 0.0111,  0.0041, -0.0139,  ...,  0.0138, -0.0088,  0.0045],\n",
       "         [ 0.0126,  0.0012, -0.0023,  ..., -0.0081,  0.0029, -0.0043],\n",
       "         [ 0.0039, -0.0017,  0.0113,  ..., -0.0071,  0.0093,  0.0075],\n",
       "         ...,\n",
       "         [-0.0073,  0.0083,  0.0133,  ..., -0.0087, -0.0004, -0.0063],\n",
       "         [-0.0142,  0.0146, -0.0029,  ..., -0.0096,  0.0057,  0.0083],\n",
       "         [ 0.0091,  0.0146, -0.0110,  ...,  0.0070, -0.0037, -0.0100]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.mlp.down_proj.lora_A.weight': tensor([[ 0.0071,  0.0061,  0.0086,  ...,  0.0077, -0.0039, -0.0025],\n",
       "         [-0.0032, -0.0036,  0.0029,  ...,  0.0011,  0.0026, -0.0080],\n",
       "         [ 0.0019, -0.0046,  0.0083,  ...,  0.0074,  0.0095, -0.0029],\n",
       "         ...,\n",
       "         [ 0.0011, -0.0083,  0.0087,  ...,  0.0017, -0.0041, -0.0014],\n",
       "         [ 0.0063, -0.0066, -0.0019,  ..., -0.0033,  0.0038,  0.0045],\n",
       "         [-0.0058,  0.0048, -0.0018,  ...,  0.0011,  0.0058, -0.0016]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.mlp.up_proj.lora_A.weight': tensor([[ 0.0038, -0.0065, -0.0093,  ..., -0.0155, -0.0007,  0.0074],\n",
       "         [ 0.0115,  0.0016, -0.0069,  ...,  0.0016,  0.0107, -0.0070],\n",
       "         [-0.0148,  0.0041,  0.0033,  ...,  0.0155, -0.0040, -0.0080],\n",
       "         ...,\n",
       "         [ 0.0023, -0.0015,  0.0145,  ..., -0.0090,  0.0035, -0.0046],\n",
       "         [-0.0098,  0.0131, -0.0015,  ...,  0.0090,  0.0017,  0.0072],\n",
       "         [-0.0021, -0.0152,  0.0025,  ..., -0.0085, -0.0106,  0.0105]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.15.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight': tensor([[-8.4991e-03, -3.6097e-04,  7.5340e-03,  ..., -8.1253e-03,\n",
       "           9.5673e-03, -4.5891e-03],\n",
       "         [-1.3512e-02,  1.0071e-02,  6.0463e-03,  ...,  4.9362e-03,\n",
       "           3.9330e-03,  1.8167e-03],\n",
       "         [-9.9335e-03,  1.2886e-02,  9.3222e-05,  ..., -4.6420e-04,\n",
       "          -2.9869e-03, -1.5053e-02],\n",
       "         ...,\n",
       "         [-5.9395e-03,  4.5357e-03,  1.3031e-02,  ...,  1.4931e-02,\n",
       "          -1.3626e-02, -3.9902e-03],\n",
       "         [ 6.0120e-03, -1.5345e-03,  1.2962e-02,  ..., -4.4594e-03,\n",
       "           1.5860e-03,  1.2154e-02],\n",
       "         [ 1.5358e-02,  1.0796e-02,  8.2703e-03,  ...,  1.2939e-02,\n",
       "          -1.1902e-02,  6.2332e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.weight': tensor([[-6.4850e-04,  9.0942e-03,  2.8687e-03,  ...,  1.1055e-02,\n",
       "          -4.4899e-03,  1.1444e-02],\n",
       "         [ 1.1024e-02, -8.2474e-03,  5.6572e-03,  ...,  7.1373e-03,\n",
       "           1.8616e-03, -1.2825e-02],\n",
       "         [-1.4748e-02, -7.0992e-03,  8.8167e-04,  ...,  1.2100e-02,\n",
       "           8.9874e-03,  3.6659e-03],\n",
       "         ...,\n",
       "         [-3.1173e-05, -1.2070e-02,  6.9475e-04,  ...,  1.1887e-02,\n",
       "           1.3405e-02, -6.9466e-03],\n",
       "         [ 9.5139e-03, -2.5558e-03,  7.5836e-03,  ...,  1.3443e-02,\n",
       "           8.3923e-03,  5.4054e-03],\n",
       "         [ 1.0460e-02, -1.3037e-03, -7.9803e-03,  ...,  2.4719e-03,\n",
       "          -5.6000e-03,  5.3673e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight': tensor([[ 0.0130, -0.0089, -0.0090,  ...,  0.0055, -0.0039,  0.0025],\n",
       "         [ 0.0076, -0.0025,  0.0018,  ..., -0.0135,  0.0089,  0.0125],\n",
       "         [ 0.0040,  0.0121,  0.0128,  ..., -0.0123,  0.0008,  0.0036],\n",
       "         ...,\n",
       "         [-0.0145, -0.0123,  0.0123,  ...,  0.0121, -0.0139, -0.0059],\n",
       "         [-0.0011,  0.0035, -0.0145,  ..., -0.0155, -0.0051,  0.0112],\n",
       "         [ 0.0096, -0.0018, -0.0138,  ..., -0.0073, -0.0155, -0.0053]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.weight': tensor([[-4.6768e-03, -1.2093e-02,  4.6844e-03,  ..., -1.0223e-02,\n",
       "           7.9880e-03, -1.2306e-02],\n",
       "         [-7.1068e-03, -6.8665e-03, -1.4107e-02,  ...,  4.6883e-03,\n",
       "           8.6060e-03,  9.4223e-03],\n",
       "         [ 6.4316e-03, -5.3177e-03, -1.2230e-02,  ..., -1.1504e-05,\n",
       "           1.0986e-02,  1.2695e-02],\n",
       "         ...,\n",
       "         [ 6.4812e-03, -1.5038e-02, -1.2636e-03,  ..., -1.2177e-02,\n",
       "          -1.1307e-02, -8.6060e-03],\n",
       "         [ 1.1322e-02, -1.4832e-02,  1.3603e-02,  ..., -1.5621e-03,\n",
       "          -5.7564e-03, -1.2085e-02],\n",
       "         [ 1.4992e-02, -1.4992e-02,  1.3237e-02,  ...,  8.4991e-03,\n",
       "          -1.4297e-02,  3.5095e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.weight': tensor([[-0.0133,  0.0032, -0.0004,  ..., -0.0133,  0.0060, -0.0128],\n",
       "         [-0.0017,  0.0011,  0.0145,  ..., -0.0045,  0.0096, -0.0146],\n",
       "         [ 0.0030,  0.0118,  0.0025,  ..., -0.0019,  0.0084, -0.0052],\n",
       "         ...,\n",
       "         [-0.0006, -0.0092, -0.0057,  ..., -0.0093,  0.0029,  0.0044],\n",
       "         [-0.0139, -0.0156, -0.0074,  ..., -0.0112,  0.0060, -0.0073],\n",
       "         [ 0.0046,  0.0044,  0.0043,  ...,  0.0097, -0.0136,  0.0132]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.mlp.down_proj.lora_A.weight': tensor([[ 1.7443e-03, -2.5082e-03, -6.3717e-05,  ..., -1.9627e-03,\n",
       "          -2.1877e-03,  4.4670e-03],\n",
       "         [-1.8482e-03, -4.3030e-03, -7.9575e-03,  ...,  2.8534e-03,\n",
       "          -2.3861e-03,  8.1787e-03],\n",
       "         [-6.9771e-03,  7.0572e-04,  1.1568e-03,  ...,  1.5891e-04,\n",
       "           8.5974e-04, -1.9703e-03],\n",
       "         ...,\n",
       "         [-4.2725e-03, -7.4673e-04, -6.0501e-03,  ..., -2.6870e-04,\n",
       "          -7.2021e-03,  2.6951e-03],\n",
       "         [-8.3313e-03,  5.8403e-03,  8.3113e-04,  ..., -2.3594e-03,\n",
       "           2.5864e-03, -8.6288e-03],\n",
       "         [-6.4125e-03, -1.9226e-03,  2.1076e-03,  ...,  3.7327e-03,\n",
       "           8.7509e-03,  6.4316e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.mlp.up_proj.lora_A.weight': tensor([[ 0.0038,  0.0071,  0.0039,  ...,  0.0038, -0.0071, -0.0107],\n",
       "         [ 0.0028, -0.0057,  0.0121,  ..., -0.0103,  0.0098, -0.0125],\n",
       "         [ 0.0032, -0.0023, -0.0082,  ...,  0.0153, -0.0080, -0.0113],\n",
       "         ...,\n",
       "         [ 0.0105, -0.0095, -0.0114,  ...,  0.0104, -0.0026,  0.0089],\n",
       "         [-0.0033,  0.0134,  0.0023,  ...,  0.0086, -0.0141,  0.0142],\n",
       "         [-0.0017,  0.0002,  0.0099,  ...,  0.0063, -0.0028, -0.0149]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.16.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight': tensor([[ 0.0070,  0.0013,  0.0042,  ..., -0.0094,  0.0148, -0.0112],\n",
       "         [-0.0094,  0.0089, -0.0145,  ..., -0.0046, -0.0035, -0.0085],\n",
       "         [ 0.0048, -0.0045, -0.0148,  ...,  0.0063, -0.0104,  0.0043],\n",
       "         ...,\n",
       "         [ 0.0115,  0.0145, -0.0137,  ...,  0.0067,  0.0087, -0.0033],\n",
       "         [-0.0097,  0.0144, -0.0103,  ..., -0.0021, -0.0037, -0.0123],\n",
       "         [ 0.0095, -0.0033, -0.0147,  ..., -0.0095,  0.0023,  0.0148]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.weight': tensor([[-0.0046,  0.0024,  0.0078,  ..., -0.0057, -0.0108,  0.0079],\n",
       "         [ 0.0098, -0.0112, -0.0132,  ...,  0.0050,  0.0035, -0.0142],\n",
       "         [ 0.0069, -0.0034, -0.0078,  ..., -0.0120,  0.0088,  0.0137],\n",
       "         ...,\n",
       "         [-0.0024,  0.0048,  0.0069,  ..., -0.0031, -0.0018,  0.0141],\n",
       "         [ 0.0043,  0.0096, -0.0129,  ..., -0.0140, -0.0143, -0.0037],\n",
       "         [-0.0027,  0.0012,  0.0126,  ..., -0.0056, -0.0118,  0.0138]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight': tensor([[ 0.0056,  0.0025, -0.0133,  ..., -0.0135,  0.0154, -0.0068],\n",
       "         [ 0.0025,  0.0117,  0.0144,  ...,  0.0004,  0.0131, -0.0057],\n",
       "         [ 0.0005, -0.0116, -0.0029,  ..., -0.0022, -0.0125, -0.0078],\n",
       "         ...,\n",
       "         [ 0.0065,  0.0005,  0.0064,  ...,  0.0060,  0.0155, -0.0088],\n",
       "         [ 0.0103, -0.0040, -0.0105,  ...,  0.0109,  0.0018,  0.0151],\n",
       "         [ 0.0092,  0.0051, -0.0140,  ...,  0.0084, -0.0039,  0.0078]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.weight': tensor([[ 0.0063, -0.0048, -0.0003,  ..., -0.0004,  0.0031, -0.0071],\n",
       "         [-0.0107,  0.0024, -0.0008,  ...,  0.0140,  0.0151, -0.0123],\n",
       "         [-0.0143, -0.0021,  0.0121,  ...,  0.0124, -0.0097, -0.0007],\n",
       "         ...,\n",
       "         [ 0.0050,  0.0132, -0.0037,  ..., -0.0022,  0.0008,  0.0009],\n",
       "         [-0.0096, -0.0086,  0.0144,  ...,  0.0005, -0.0100,  0.0073],\n",
       "         [-0.0049, -0.0063,  0.0058,  ..., -0.0107,  0.0073,  0.0152]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.weight': tensor([[ 0.0089,  0.0129, -0.0013,  ..., -0.0076, -0.0135,  0.0146],\n",
       "         [ 0.0090, -0.0029,  0.0044,  ...,  0.0147,  0.0027,  0.0147],\n",
       "         [ 0.0085, -0.0122,  0.0113,  ...,  0.0005,  0.0133, -0.0120],\n",
       "         ...,\n",
       "         [-0.0014,  0.0076,  0.0123,  ...,  0.0015, -0.0016,  0.0074],\n",
       "         [ 0.0066, -0.0143,  0.0030,  ...,  0.0067,  0.0023,  0.0021],\n",
       "         [ 0.0093, -0.0101,  0.0060,  ...,  0.0009,  0.0133,  0.0102]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.mlp.down_proj.lora_A.weight': tensor([[ 7.7820e-04, -4.3831e-03, -9.6619e-05,  ...,  6.4430e-03,\n",
       "          -6.1455e-03,  6.4583e-03],\n",
       "         [ 7.9422e-03,  5.1451e-04,  2.8248e-03,  ...,  3.6507e-03,\n",
       "           3.6144e-03,  9.9754e-04],\n",
       "         [-3.3550e-03, -3.1910e-03, -4.9438e-03,  ..., -1.6308e-03,\n",
       "          -6.8359e-03, -5.8079e-04],\n",
       "         ...,\n",
       "         [-3.6526e-03, -8.3008e-03,  6.2141e-03,  ...,  3.4370e-03,\n",
       "           2.4548e-03,  3.3207e-03],\n",
       "         [ 1.3142e-03, -7.9880e-03, -2.5024e-03,  ..., -1.6842e-03,\n",
       "           6.1703e-04,  8.2855e-03],\n",
       "         [ 2.3499e-03,  5.7745e-04,  5.0087e-03,  ...,  7.3242e-04,\n",
       "          -1.2007e-03,  8.1940e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.mlp.up_proj.lora_A.weight': tensor([[-0.0017,  0.0127,  0.0152,  ...,  0.0149,  0.0120,  0.0123],\n",
       "         [ 0.0078, -0.0090, -0.0012,  ..., -0.0042, -0.0103, -0.0085],\n",
       "         [ 0.0011, -0.0002, -0.0098,  ...,  0.0135, -0.0094,  0.0075],\n",
       "         ...,\n",
       "         [-0.0080,  0.0010, -0.0074,  ..., -0.0066, -0.0002,  0.0053],\n",
       "         [-0.0131,  0.0119, -0.0044,  ..., -0.0050, -0.0048, -0.0025],\n",
       "         [ 0.0113, -0.0106, -0.0142,  ...,  0.0031,  0.0154, -0.0154]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.17.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight': tensor([[ 0.0088, -0.0012, -0.0101,  ..., -0.0015, -0.0126,  0.0008],\n",
       "         [-0.0067, -0.0125, -0.0012,  ..., -0.0084,  0.0057,  0.0081],\n",
       "         [ 0.0128,  0.0056, -0.0090,  ...,  0.0039,  0.0093, -0.0131],\n",
       "         ...,\n",
       "         [-0.0152,  0.0037, -0.0113,  ...,  0.0126,  0.0113, -0.0145],\n",
       "         [-0.0017, -0.0034,  0.0116,  ...,  0.0036,  0.0087,  0.0001],\n",
       "         [ 0.0053, -0.0012,  0.0058,  ...,  0.0108, -0.0052,  0.0072]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.weight': tensor([[-8.2672e-05,  5.2719e-03, -5.0430e-03,  ...,  8.9874e-03,\n",
       "           5.8479e-03, -3.1281e-03],\n",
       "         [-1.6317e-03,  9.1476e-03, -9.4681e-03,  ..., -1.2337e-02,\n",
       "           7.6294e-03, -9.6588e-03],\n",
       "         [ 4.8447e-03, -6.9504e-03,  3.2253e-03,  ..., -1.1238e-02,\n",
       "          -4.7040e-04, -2.1477e-03],\n",
       "         ...,\n",
       "         [-4.3464e-04,  2.4719e-03, -3.1490e-03,  ...,  1.5022e-02,\n",
       "           5.8899e-03,  1.6069e-03],\n",
       "         [-5.5199e-03,  1.3771e-02, -1.0254e-02,  ...,  2.3746e-03,\n",
       "          -5.4779e-03, -1.4877e-02],\n",
       "         [ 9.7580e-03,  1.8845e-03,  1.3443e-02,  ...,  6.1264e-03,\n",
       "           3.4351e-03,  3.3188e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight': tensor([[ 0.0048,  0.0090, -0.0031,  ..., -0.0092,  0.0067, -0.0008],\n",
       "         [-0.0149,  0.0061,  0.0100,  ...,  0.0027,  0.0096, -0.0123],\n",
       "         [ 0.0118, -0.0149,  0.0124,  ..., -0.0041, -0.0116,  0.0010],\n",
       "         ...,\n",
       "         [ 0.0090, -0.0119,  0.0144,  ...,  0.0100, -0.0019,  0.0009],\n",
       "         [-0.0018,  0.0140, -0.0015,  ..., -0.0137,  0.0114, -0.0148],\n",
       "         [ 0.0129, -0.0135, -0.0064,  ..., -0.0018,  0.0117,  0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.weight': tensor([[-0.0137,  0.0098, -0.0082,  ...,  0.0114, -0.0083,  0.0132],\n",
       "         [ 0.0053,  0.0098,  0.0096,  ...,  0.0090, -0.0085, -0.0044],\n",
       "         [ 0.0122, -0.0098, -0.0065,  ...,  0.0152, -0.0041, -0.0103],\n",
       "         ...,\n",
       "         [ 0.0057,  0.0052,  0.0022,  ...,  0.0072, -0.0023,  0.0106],\n",
       "         [ 0.0129, -0.0142, -0.0086,  ..., -0.0126,  0.0033, -0.0024],\n",
       "         [-0.0106,  0.0096, -0.0117,  ..., -0.0030,  0.0130, -0.0145]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.weight': tensor([[-0.0119, -0.0094, -0.0113,  ..., -0.0037,  0.0059,  0.0081],\n",
       "         [ 0.0095, -0.0129, -0.0039,  ...,  0.0069,  0.0039,  0.0025],\n",
       "         [ 0.0097, -0.0093,  0.0106,  ...,  0.0132,  0.0120, -0.0136],\n",
       "         ...,\n",
       "         [-0.0076, -0.0146, -0.0037,  ...,  0.0096,  0.0056,  0.0072],\n",
       "         [-0.0012,  0.0150, -0.0089,  ..., -0.0147,  0.0083,  0.0016],\n",
       "         [-0.0128,  0.0023, -0.0154,  ...,  0.0152,  0.0102, -0.0010]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.mlp.down_proj.lora_A.weight': tensor([[ 0.0065,  0.0072, -0.0031,  ...,  0.0071, -0.0087, -0.0002],\n",
       "         [-0.0001, -0.0057, -0.0074,  ..., -0.0060, -0.0012,  0.0012],\n",
       "         [ 0.0006,  0.0063, -0.0002,  ..., -0.0003, -0.0080,  0.0010],\n",
       "         ...,\n",
       "         [-0.0021, -0.0066,  0.0037,  ..., -0.0072,  0.0010,  0.0020],\n",
       "         [-0.0015,  0.0063,  0.0034,  ..., -0.0085, -0.0042, -0.0094],\n",
       "         [-0.0093, -0.0067, -0.0088,  ..., -0.0012, -0.0026, -0.0076]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.mlp.up_proj.lora_A.weight': tensor([[ 0.0107,  0.0011, -0.0039,  ...,  0.0051, -0.0118,  0.0071],\n",
       "         [ 0.0147, -0.0002, -0.0023,  ..., -0.0114,  0.0017,  0.0043],\n",
       "         [ 0.0103,  0.0107,  0.0118,  ...,  0.0074, -0.0046, -0.0140],\n",
       "         ...,\n",
       "         [-0.0145, -0.0069, -0.0149,  ...,  0.0138,  0.0097,  0.0091],\n",
       "         [-0.0007,  0.0084, -0.0060,  ..., -0.0047, -0.0114, -0.0143],\n",
       "         [ 0.0081, -0.0142, -0.0093,  ..., -0.0137,  0.0002,  0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.18.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight': tensor([[ 0.0105,  0.0121,  0.0010,  ..., -0.0092, -0.0032, -0.0077],\n",
       "         [ 0.0114, -0.0134,  0.0151,  ..., -0.0090,  0.0084,  0.0113],\n",
       "         [-0.0154,  0.0144,  0.0028,  ...,  0.0145,  0.0089,  0.0009],\n",
       "         ...,\n",
       "         [ 0.0155, -0.0080, -0.0017,  ..., -0.0124,  0.0131, -0.0052],\n",
       "         [-0.0024,  0.0095, -0.0061,  ...,  0.0058, -0.0098, -0.0150],\n",
       "         [-0.0117, -0.0057,  0.0109,  ...,  0.0076, -0.0153,  0.0016]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.weight': tensor([[-0.0001,  0.0047,  0.0060,  ...,  0.0009,  0.0013, -0.0155],\n",
       "         [-0.0028,  0.0036,  0.0097,  ...,  0.0039, -0.0121,  0.0052],\n",
       "         [ 0.0129,  0.0102,  0.0130,  ...,  0.0108, -0.0003, -0.0041],\n",
       "         ...,\n",
       "         [-0.0014,  0.0026, -0.0078,  ..., -0.0004,  0.0013,  0.0081],\n",
       "         [-0.0099,  0.0139, -0.0133,  ..., -0.0110, -0.0027,  0.0091],\n",
       "         [ 0.0085,  0.0118, -0.0021,  ..., -0.0114,  0.0008,  0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight': tensor([[ 0.0052,  0.0130,  0.0065,  ...,  0.0010,  0.0098, -0.0009],\n",
       "         [ 0.0145, -0.0025,  0.0050,  ...,  0.0019,  0.0116, -0.0032],\n",
       "         [ 0.0007,  0.0070,  0.0060,  ..., -0.0122, -0.0102, -0.0081],\n",
       "         ...,\n",
       "         [ 0.0053,  0.0054, -0.0139,  ...,  0.0050,  0.0048, -0.0045],\n",
       "         [ 0.0079, -0.0016, -0.0109,  ...,  0.0033, -0.0076,  0.0031],\n",
       "         [ 0.0122,  0.0136, -0.0051,  ..., -0.0050, -0.0141,  0.0057]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.weight': tensor([[-0.0011,  0.0044,  0.0006,  ..., -0.0107, -0.0106, -0.0050],\n",
       "         [ 0.0065, -0.0010, -0.0118,  ...,  0.0137,  0.0026, -0.0144],\n",
       "         [ 0.0037, -0.0084, -0.0146,  ...,  0.0105,  0.0118,  0.0084],\n",
       "         ...,\n",
       "         [ 0.0040, -0.0093, -0.0066,  ..., -0.0036, -0.0016,  0.0131],\n",
       "         [-0.0123,  0.0081, -0.0139,  ...,  0.0065,  0.0047, -0.0090],\n",
       "         [-0.0005,  0.0082, -0.0059,  ..., -0.0023,  0.0144,  0.0114]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.weight': tensor([[ 0.0030, -0.0072,  0.0123,  ...,  0.0064, -0.0089,  0.0094],\n",
       "         [-0.0088, -0.0065,  0.0097,  ..., -0.0031,  0.0026,  0.0127],\n",
       "         [ 0.0142, -0.0053, -0.0075,  ...,  0.0042,  0.0050,  0.0022],\n",
       "         ...,\n",
       "         [ 0.0144,  0.0062,  0.0076,  ..., -0.0140,  0.0108, -0.0049],\n",
       "         [-0.0019, -0.0128,  0.0099,  ..., -0.0135,  0.0023, -0.0150],\n",
       "         [ 0.0054,  0.0052,  0.0126,  ..., -0.0032,  0.0149, -0.0127]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.mlp.down_proj.lora_A.weight': tensor([[-0.0015, -0.0033,  0.0089,  ..., -0.0056,  0.0056,  0.0070],\n",
       "         [-0.0035,  0.0038, -0.0069,  ...,  0.0049,  0.0030,  0.0022],\n",
       "         [-0.0080,  0.0053, -0.0039,  ..., -0.0049,  0.0036,  0.0016],\n",
       "         ...,\n",
       "         [-0.0064,  0.0088, -0.0077,  ..., -0.0006,  0.0062, -0.0070],\n",
       "         [ 0.0067,  0.0034, -0.0051,  ...,  0.0054, -0.0072, -0.0037],\n",
       "         [-0.0092, -0.0060,  0.0044,  ...,  0.0031, -0.0093,  0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.mlp.up_proj.lora_A.weight': tensor([[ 0.0134,  0.0138, -0.0051,  ...,  0.0025, -0.0022,  0.0008],\n",
       "         [-0.0107,  0.0143,  0.0003,  ..., -0.0118, -0.0018, -0.0144],\n",
       "         [ 0.0008, -0.0152,  0.0054,  ..., -0.0062,  0.0130,  0.0037],\n",
       "         ...,\n",
       "         [ 0.0079,  0.0076, -0.0152,  ..., -0.0119, -0.0026,  0.0151],\n",
       "         [-0.0145, -0.0060,  0.0128,  ..., -0.0139, -0.0014, -0.0037],\n",
       "         [ 0.0098,  0.0041, -0.0130,  ...,  0.0085, -0.0130, -0.0108]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.19.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight': tensor([[-0.0033,  0.0124, -0.0117,  ..., -0.0093,  0.0129, -0.0026],\n",
       "         [-0.0059,  0.0137,  0.0057,  ...,  0.0143,  0.0045, -0.0014],\n",
       "         [-0.0038,  0.0138,  0.0089,  ...,  0.0102,  0.0088,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0118, -0.0106,  0.0112,  ...,  0.0101, -0.0070,  0.0130],\n",
       "         [-0.0027,  0.0050, -0.0105,  ..., -0.0007, -0.0009, -0.0081],\n",
       "         [ 0.0104,  0.0060,  0.0005,  ...,  0.0151, -0.0156,  0.0083]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.weight': tensor([[-0.0104, -0.0030, -0.0090,  ...,  0.0024,  0.0085,  0.0112],\n",
       "         [ 0.0047, -0.0075,  0.0070,  ..., -0.0096,  0.0029, -0.0139],\n",
       "         [-0.0102,  0.0114, -0.0035,  ..., -0.0134, -0.0085, -0.0103],\n",
       "         ...,\n",
       "         [ 0.0014, -0.0056,  0.0054,  ..., -0.0100, -0.0052, -0.0149],\n",
       "         [ 0.0118,  0.0043, -0.0031,  ...,  0.0138, -0.0135,  0.0135],\n",
       "         [-0.0090,  0.0097, -0.0136,  ..., -0.0011, -0.0032,  0.0034]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight': tensor([[ 0.0100, -0.0089,  0.0031,  ..., -0.0144, -0.0054, -0.0153],\n",
       "         [ 0.0073, -0.0137, -0.0132,  ..., -0.0017,  0.0012, -0.0139],\n",
       "         [-0.0096,  0.0102,  0.0083,  ..., -0.0022, -0.0009, -0.0146],\n",
       "         ...,\n",
       "         [-0.0006,  0.0106, -0.0081,  ...,  0.0077, -0.0075,  0.0074],\n",
       "         [-0.0099, -0.0034,  0.0112,  ...,  0.0099, -0.0050,  0.0037],\n",
       "         [-0.0046,  0.0007,  0.0151,  ...,  0.0078,  0.0092,  0.0079]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.weight': tensor([[ 0.0083,  0.0041,  0.0106,  ..., -0.0054, -0.0122,  0.0065],\n",
       "         [ 0.0093,  0.0019, -0.0119,  ..., -0.0037,  0.0104,  0.0006],\n",
       "         [-0.0150,  0.0151, -0.0110,  ...,  0.0071, -0.0096,  0.0054],\n",
       "         ...,\n",
       "         [-0.0013, -0.0055, -0.0115,  ..., -0.0135, -0.0072,  0.0097],\n",
       "         [ 0.0155, -0.0103, -0.0057,  ..., -0.0045,  0.0098,  0.0017],\n",
       "         [-0.0141,  0.0080, -0.0100,  ..., -0.0085,  0.0098, -0.0074]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.weight': tensor([[ 0.0020, -0.0143,  0.0139,  ..., -0.0139, -0.0138, -0.0065],\n",
       "         [-0.0096,  0.0051,  0.0029,  ...,  0.0057,  0.0102, -0.0073],\n",
       "         [ 0.0017, -0.0123,  0.0099,  ...,  0.0098, -0.0060, -0.0103],\n",
       "         ...,\n",
       "         [ 0.0121,  0.0007, -0.0032,  ...,  0.0124, -0.0061, -0.0091],\n",
       "         [-0.0148, -0.0099,  0.0107,  ..., -0.0083,  0.0052,  0.0122],\n",
       "         [ 0.0004, -0.0108,  0.0101,  ..., -0.0150, -0.0077, -0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.mlp.down_proj.lora_A.weight': tensor([[-0.0032, -0.0072,  0.0070,  ...,  0.0006,  0.0048,  0.0063],\n",
       "         [-0.0036,  0.0090,  0.0035,  ...,  0.0074, -0.0090,  0.0030],\n",
       "         [-0.0064,  0.0088, -0.0049,  ...,  0.0039,  0.0066, -0.0037],\n",
       "         ...,\n",
       "         [-0.0055, -0.0018,  0.0056,  ..., -0.0064,  0.0090,  0.0012],\n",
       "         [ 0.0015, -0.0018, -0.0023,  ...,  0.0063,  0.0091,  0.0071],\n",
       "         [ 0.0023, -0.0063,  0.0090,  ...,  0.0003,  0.0021, -0.0081]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.mlp.up_proj.lora_A.weight': tensor([[-8.5602e-03, -6.3057e-03, -9.6512e-03,  ..., -2.9373e-03,\n",
       "          -2.2221e-03,  8.8043e-03],\n",
       "         [-8.8272e-03,  1.8167e-04, -1.0956e-02,  ..., -1.0696e-02,\n",
       "          -1.3557e-02,  5.0354e-03],\n",
       "         [ 2.3098e-03,  1.2367e-02,  4.1008e-03,  ...,  9.1324e-03,\n",
       "           2.3746e-03, -8.1635e-03],\n",
       "         ...,\n",
       "         [ 8.4000e-03,  8.1787e-03,  1.4656e-02,  ...,  8.5602e-03,\n",
       "          -1.2123e-02, -9.5139e-03],\n",
       "         [-9.2506e-05, -1.1093e-02, -2.8744e-03,  ...,  1.3107e-02,\n",
       "           6.5002e-03, -1.3336e-02],\n",
       "         [ 1.1766e-04,  1.1108e-02, -1.0963e-02,  ...,  3.0384e-03,\n",
       "          -1.1452e-02, -9.2010e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.20.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight': tensor([[ 0.0033, -0.0150,  0.0135,  ..., -0.0129,  0.0129,  0.0135],\n",
       "         [ 0.0113, -0.0041, -0.0040,  ..., -0.0109,  0.0087,  0.0149],\n",
       "         [ 0.0144,  0.0133, -0.0034,  ...,  0.0089,  0.0020, -0.0054],\n",
       "         ...,\n",
       "         [-0.0060,  0.0009, -0.0125,  ...,  0.0009,  0.0089, -0.0078],\n",
       "         [ 0.0061, -0.0102,  0.0030,  ..., -0.0135,  0.0040, -0.0123],\n",
       "         [ 0.0023, -0.0132,  0.0073,  ..., -0.0108,  0.0153, -0.0109]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.weight': tensor([[ 2.0123e-03, -9.5978e-03, -9.7573e-05,  ..., -3.6335e-03,\n",
       "          -1.5320e-02,  2.8839e-03],\n",
       "         [ 1.5518e-02, -7.5388e-04,  1.2650e-02,  ...,  5.6686e-03,\n",
       "           6.6795e-03,  1.1711e-02],\n",
       "         [-6.2943e-04,  1.2875e-03, -4.5166e-03,  ...,  1.6701e-04,\n",
       "          -1.4267e-02,  1.0452e-02],\n",
       "         ...,\n",
       "         [ 3.8261e-03, -1.0612e-02, -7.2327e-03,  ...,  8.8882e-03,\n",
       "          -5.6076e-03, -1.3771e-02],\n",
       "         [ 6.5422e-03, -9.4986e-03,  3.7498e-03,  ...,  1.1642e-02,\n",
       "          -1.5305e-02,  5.9586e-03],\n",
       "         [-1.3939e-02,  6.7520e-04,  1.5045e-02,  ..., -1.0399e-02,\n",
       "           4.9095e-03,  2.4929e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight': tensor([[-0.0141,  0.0032, -0.0031,  ...,  0.0079,  0.0121,  0.0098],\n",
       "         [-0.0144, -0.0032,  0.0099,  ..., -0.0032, -0.0119, -0.0154],\n",
       "         [ 0.0053, -0.0148, -0.0118,  ..., -0.0102, -0.0154,  0.0127],\n",
       "         ...,\n",
       "         [-0.0086, -0.0022, -0.0130,  ...,  0.0064,  0.0045,  0.0067],\n",
       "         [-0.0015,  0.0078, -0.0072,  ..., -0.0002, -0.0145, -0.0013],\n",
       "         [-0.0044,  0.0005, -0.0050,  ..., -0.0047, -0.0082, -0.0035]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.weight': tensor([[ 0.0007,  0.0113, -0.0085,  ...,  0.0096, -0.0073, -0.0130],\n",
       "         [ 0.0067, -0.0156, -0.0052,  ...,  0.0092,  0.0071, -0.0087],\n",
       "         [ 0.0023,  0.0032,  0.0062,  ..., -0.0039, -0.0011, -0.0106],\n",
       "         ...,\n",
       "         [ 0.0020, -0.0146,  0.0136,  ..., -0.0054,  0.0083,  0.0138],\n",
       "         [-0.0065, -0.0008,  0.0065,  ..., -0.0061,  0.0015, -0.0066],\n",
       "         [ 0.0134, -0.0154,  0.0051,  ...,  0.0017,  0.0004, -0.0117]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.weight': tensor([[ 0.0139, -0.0118,  0.0145,  ...,  0.0056,  0.0156, -0.0019],\n",
       "         [ 0.0013, -0.0099, -0.0145,  ..., -0.0125,  0.0107,  0.0135],\n",
       "         [-0.0072, -0.0044, -0.0153,  ..., -0.0075,  0.0155,  0.0084],\n",
       "         ...,\n",
       "         [ 0.0064,  0.0120,  0.0097,  ..., -0.0072,  0.0094,  0.0090],\n",
       "         [ 0.0093, -0.0037, -0.0072,  ..., -0.0078,  0.0053, -0.0052],\n",
       "         [-0.0061, -0.0073,  0.0092,  ...,  0.0022,  0.0078,  0.0114]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.mlp.down_proj.lora_A.weight': tensor([[-7.4234e-03,  2.7347e-04, -6.4812e-03,  ..., -6.4964e-03,\n",
       "           7.3738e-03,  3.5286e-03],\n",
       "         [-5.5809e-03, -6.5804e-03,  9.3155e-03,  ...,  7.0190e-03,\n",
       "          -7.4959e-03, -7.4501e-03],\n",
       "         [-7.6637e-03,  5.5733e-03,  2.3022e-03,  ...,  2.1439e-03,\n",
       "          -2.0580e-03, -5.8937e-03],\n",
       "         ...,\n",
       "         [-8.9340e-03,  2.6093e-03,  2.3613e-03,  ..., -1.4710e-04,\n",
       "          -2.3899e-03, -3.5191e-03],\n",
       "         [-2.9159e-04, -3.9139e-03, -3.8376e-03,  ..., -2.1553e-03,\n",
       "           4.2915e-03, -2.4676e-04],\n",
       "         [ 2.7428e-03, -6.6719e-03, -8.4076e-03,  ..., -1.7881e-06,\n",
       "          -9.3231e-03, -7.2632e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.mlp.up_proj.lora_A.weight': tensor([[-5.7869e-03,  6.7863e-03, -7.5836e-03,  ...,  5.4359e-03,\n",
       "           1.1055e-02, -1.2314e-02],\n",
       "         [ 1.9083e-03, -5.6229e-03,  2.4662e-03,  ...,  8.7166e-04,\n",
       "           1.2848e-02,  6.5041e-03],\n",
       "         [ 8.5211e-04, -1.5099e-02,  3.5763e-03,  ...,  4.0054e-04,\n",
       "           1.6813e-03, -8.5602e-03],\n",
       "         ...,\n",
       "         [-4.3030e-03, -9.8953e-03,  1.5152e-02,  ...,  4.9591e-03,\n",
       "          -8.5950e-05,  5.7697e-04],\n",
       "         [-1.4565e-02,  5.8289e-03, -1.3725e-02,  ...,  5.9128e-04,\n",
       "          -4.9477e-03, -1.4732e-02],\n",
       "         [-9.4910e-03,  1.1551e-02, -1.5457e-02,  ..., -1.3992e-02,\n",
       "           6.7711e-03,  7.6447e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.21.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight': tensor([[-0.0073,  0.0010, -0.0098,  ...,  0.0025,  0.0130,  0.0043],\n",
       "         [ 0.0091,  0.0053,  0.0046,  ..., -0.0105, -0.0027, -0.0088],\n",
       "         [ 0.0139,  0.0071,  0.0155,  ..., -0.0027,  0.0057, -0.0006],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0087,  0.0044,  ..., -0.0032, -0.0139, -0.0037],\n",
       "         [-0.0032,  0.0055,  0.0042,  ...,  0.0064, -0.0133,  0.0077],\n",
       "         [-0.0084, -0.0118,  0.0089,  ...,  0.0144,  0.0032, -0.0153]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.weight': tensor([[ 0.0088,  0.0121,  0.0077,  ..., -0.0099, -0.0069, -0.0033],\n",
       "         [-0.0136,  0.0018, -0.0128,  ...,  0.0119,  0.0036, -0.0078],\n",
       "         [-0.0091, -0.0045, -0.0138,  ..., -0.0067, -0.0003, -0.0038],\n",
       "         ...,\n",
       "         [ 0.0051, -0.0025, -0.0137,  ...,  0.0040, -0.0123, -0.0101],\n",
       "         [ 0.0136, -0.0079,  0.0134,  ...,  0.0109,  0.0139, -0.0047],\n",
       "         [-0.0013, -0.0087,  0.0047,  ...,  0.0018, -0.0022,  0.0111]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight': tensor([[ 0.0023, -0.0115, -0.0067,  ..., -0.0103,  0.0138,  0.0043],\n",
       "         [-0.0147,  0.0133,  0.0020,  ..., -0.0149, -0.0116,  0.0014],\n",
       "         [-0.0071, -0.0113, -0.0005,  ..., -0.0068,  0.0065,  0.0096],\n",
       "         ...,\n",
       "         [ 0.0099,  0.0072,  0.0122,  ...,  0.0024, -0.0049, -0.0036],\n",
       "         [ 0.0110,  0.0121, -0.0116,  ..., -0.0059,  0.0047, -0.0011],\n",
       "         [ 0.0090,  0.0080,  0.0023,  ..., -0.0013,  0.0026, -0.0020]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.weight': tensor([[ 0.0019,  0.0140, -0.0153,  ...,  0.0113,  0.0052,  0.0094],\n",
       "         [ 0.0135, -0.0008, -0.0047,  ...,  0.0130, -0.0137,  0.0021],\n",
       "         [ 0.0039, -0.0050,  0.0153,  ...,  0.0099,  0.0125,  0.0110],\n",
       "         ...,\n",
       "         [ 0.0052,  0.0080,  0.0049,  ..., -0.0061,  0.0016, -0.0088],\n",
       "         [-0.0128, -0.0081, -0.0042,  ..., -0.0141,  0.0015, -0.0008],\n",
       "         [-0.0083,  0.0072, -0.0078,  ..., -0.0043, -0.0118,  0.0105]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.weight': tensor([[ 0.0028,  0.0108,  0.0024,  ...,  0.0131,  0.0068,  0.0106],\n",
       "         [ 0.0143,  0.0023,  0.0027,  ..., -0.0126,  0.0115,  0.0152],\n",
       "         [ 0.0014, -0.0044,  0.0064,  ..., -0.0029, -0.0023, -0.0077],\n",
       "         ...,\n",
       "         [ 0.0117,  0.0035,  0.0087,  ..., -0.0067, -0.0112,  0.0112],\n",
       "         [ 0.0029, -0.0020, -0.0103,  ...,  0.0049, -0.0036, -0.0152],\n",
       "         [ 0.0059,  0.0073, -0.0087,  ...,  0.0043,  0.0065, -0.0110]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.mlp.down_proj.lora_A.weight': tensor([[ 6.0844e-03, -4.8447e-03, -2.0409e-03,  ...,  3.6736e-03,\n",
       "          -4.4632e-03, -5.1842e-03],\n",
       "         [ 4.5357e-03,  3.4180e-03, -8.0185e-03,  ...,  8.5678e-03,\n",
       "          -6.2904e-03,  7.8888e-03],\n",
       "         [ 6.9160e-03, -8.9111e-03,  7.3929e-03,  ...,  7.6447e-03,\n",
       "          -2.2755e-03,  5.6190e-03],\n",
       "         ...,\n",
       "         [-2.8896e-03, -1.7853e-03,  7.9966e-04,  ...,  5.7068e-03,\n",
       "          -4.4250e-04,  1.6251e-03],\n",
       "         [ 2.2602e-03,  7.5378e-03,  6.8188e-05,  ...,  6.0921e-03,\n",
       "           2.5806e-03, -9.1705e-03],\n",
       "         [ 1.2732e-03,  9.3384e-03,  6.8626e-03,  ..., -4.3716e-03,\n",
       "          -7.0572e-03, -4.4670e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.mlp.up_proj.lora_A.weight': tensor([[ 1.5381e-02,  4.0779e-03, -5.5962e-03,  ..., -1.3704e-03,\n",
       "          -6.6757e-03,  5.6496e-03],\n",
       "         [-2.7046e-03,  5.4016e-03, -1.1292e-02,  ...,  1.6346e-03,\n",
       "          -8.9569e-03,  1.3901e-02],\n",
       "         [ 6.0349e-03,  2.8725e-03,  1.1055e-02,  ...,  3.8481e-04,\n",
       "          -1.2001e-02, -5.1498e-03],\n",
       "         ...,\n",
       "         [ 4.7569e-03,  8.8882e-03, -1.2062e-02,  ...,  8.2474e-03,\n",
       "          -1.1940e-02,  1.4221e-02],\n",
       "         [ 1.2573e-02,  3.7594e-03, -9.7513e-05,  ..., -6.9189e-04,\n",
       "           1.5266e-02,  1.2390e-02],\n",
       "         [ 7.0839e-03,  6.0120e-03, -4.6158e-03,  ..., -3.9711e-03,\n",
       "           1.0002e-02, -1.4557e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.22.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight': tensor([[ 1.4015e-02, -1.9875e-03,  1.4435e-02,  ..., -7.4730e-03,\n",
       "           1.5175e-02, -2.6550e-03],\n",
       "         [ 1.7738e-03, -7.3090e-03,  9.8801e-03,  ..., -1.4389e-02,\n",
       "          -6.1035e-03,  5.0087e-03],\n",
       "         [ 7.3509e-03, -5.8479e-03,  1.3885e-02,  ...,  1.0658e-02,\n",
       "          -8.1863e-03, -1.0696e-02],\n",
       "         ...,\n",
       "         [ 1.4404e-02,  1.0712e-02,  2.5711e-03,  ...,  4.9667e-03,\n",
       "          -5.1117e-04, -2.5139e-03],\n",
       "         [-1.2390e-02,  1.1139e-02,  3.9673e-03,  ..., -1.3588e-02,\n",
       "          -5.0316e-03,  1.3304e-03],\n",
       "         [ 1.3634e-02,  9.9030e-03,  6.7253e-03,  ..., -1.5053e-02,\n",
       "           4.3983e-03,  3.5107e-05]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.weight': tensor([[-0.0156, -0.0087,  0.0090,  ..., -0.0002,  0.0101,  0.0151],\n",
       "         [-0.0040, -0.0058, -0.0047,  ..., -0.0123, -0.0025, -0.0126],\n",
       "         [ 0.0051,  0.0058, -0.0155,  ..., -0.0012,  0.0068,  0.0050],\n",
       "         ...,\n",
       "         [ 0.0005,  0.0020,  0.0029,  ..., -0.0123, -0.0152, -0.0042],\n",
       "         [ 0.0133,  0.0013,  0.0106,  ..., -0.0085, -0.0014, -0.0009],\n",
       "         [ 0.0117,  0.0046,  0.0047,  ...,  0.0027, -0.0149,  0.0153]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight': tensor([[-3.4447e-03,  1.0345e-02, -1.1299e-02,  ...,  1.3161e-03,\n",
       "          -1.4557e-02, -4.5204e-03],\n",
       "         [ 8.9347e-05, -4.6921e-03, -8.8654e-03,  ..., -3.8528e-03,\n",
       "          -4.6349e-03, -5.8441e-03],\n",
       "         [-1.5060e-02, -5.5695e-03,  7.3147e-04,  ..., -2.7752e-04,\n",
       "          -1.6861e-03, -4.3030e-03],\n",
       "         ...,\n",
       "         [ 6.0425e-03, -1.3769e-04, -4.4518e-03,  ...,  8.9951e-03,\n",
       "           1.3802e-02,  5.5504e-03],\n",
       "         [ 3.9711e-03,  1.4580e-02, -2.5940e-03,  ..., -2.4242e-03,\n",
       "          -5.7907e-03,  2.0733e-03],\n",
       "         [ 5.5695e-03, -1.3351e-03, -4.6196e-03,  ..., -1.5137e-02,\n",
       "           2.3804e-03, -1.2550e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.weight': tensor([[ 0.0013, -0.0146,  0.0086,  ..., -0.0116,  0.0099,  0.0065],\n",
       "         [-0.0002,  0.0003,  0.0041,  ..., -0.0065, -0.0099, -0.0026],\n",
       "         [ 0.0098,  0.0121,  0.0031,  ..., -0.0080, -0.0044, -0.0086],\n",
       "         ...,\n",
       "         [ 0.0071,  0.0135, -0.0155,  ...,  0.0013, -0.0040, -0.0090],\n",
       "         [-0.0046,  0.0039,  0.0118,  ...,  0.0119,  0.0037,  0.0139],\n",
       "         [ 0.0010, -0.0002, -0.0148,  ...,  0.0022,  0.0095,  0.0072]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.weight': tensor([[ 0.0044,  0.0018,  0.0139,  ..., -0.0155,  0.0043, -0.0135],\n",
       "         [ 0.0089, -0.0038,  0.0069,  ..., -0.0031, -0.0028, -0.0057],\n",
       "         [-0.0043, -0.0048, -0.0144,  ..., -0.0039,  0.0029,  0.0086],\n",
       "         ...,\n",
       "         [-0.0036,  0.0116,  0.0027,  ...,  0.0108,  0.0048,  0.0153],\n",
       "         [-0.0102,  0.0024, -0.0059,  ..., -0.0020, -0.0132, -0.0032],\n",
       "         [-0.0056,  0.0149,  0.0131,  ..., -0.0135, -0.0154,  0.0076]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.mlp.down_proj.lora_A.weight': tensor([[-0.0072, -0.0032,  0.0025,  ...,  0.0075,  0.0084,  0.0088],\n",
       "         [-0.0006,  0.0057, -0.0027,  ..., -0.0028,  0.0092,  0.0068],\n",
       "         [ 0.0022, -0.0078,  0.0072,  ...,  0.0092,  0.0050, -0.0013],\n",
       "         ...,\n",
       "         [-0.0017, -0.0016, -0.0048,  ...,  0.0025, -0.0012,  0.0006],\n",
       "         [ 0.0034,  0.0042, -0.0089,  ...,  0.0091, -0.0004,  0.0084],\n",
       "         [-0.0046, -0.0013,  0.0060,  ..., -0.0090,  0.0072, -0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.mlp.up_proj.lora_A.weight': tensor([[-8.1787e-03, -9.9030e-03, -5.6152e-03,  ..., -3.9635e-03,\n",
       "           7.7629e-03, -1.0586e-03],\n",
       "         [ 3.1700e-03,  1.1971e-02, -4.3297e-03,  ...,  1.1703e-02,\n",
       "           2.7637e-03,  1.2550e-02],\n",
       "         [-1.5274e-02, -1.5076e-02,  1.2199e-02,  ...,  9.5749e-03,\n",
       "          -3.9978e-03,  8.6746e-03],\n",
       "         ...,\n",
       "         [-3.3665e-03,  1.6470e-03,  1.3756e-02,  ...,  3.9339e-04,\n",
       "          -1.1391e-02,  8.1658e-05],\n",
       "         [-5.1117e-03, -1.3329e-02, -8.4152e-03,  ...,  4.4746e-03,\n",
       "          -1.1986e-02,  1.2634e-02],\n",
       "         [ 6.0558e-04,  1.5137e-02,  5.7335e-03,  ...,  5.2376e-03,\n",
       "           3.0594e-03, -5.4550e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.23.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight': tensor([[-6.8893e-03, -5.8937e-03, -9.4070e-03,  ...,  6.4201e-03,\n",
       "           6.0043e-03,  4.9896e-03],\n",
       "         [ 5.6572e-03, -2.7485e-03,  1.1864e-02,  ...,  1.3145e-02,\n",
       "           1.2436e-02,  2.3632e-03],\n",
       "         [-1.5228e-02, -8.5754e-03,  4.8141e-03,  ..., -7.1411e-03,\n",
       "          -3.2692e-03,  7.8678e-05],\n",
       "         ...,\n",
       "         [-8.6060e-03,  1.4248e-03,  5.6686e-03,  ...,  1.4801e-02,\n",
       "          -1.4519e-02, -7.4081e-03],\n",
       "         [-1.2901e-02, -7.1030e-03, -3.1738e-03,  ...,  1.0002e-02,\n",
       "          -2.7161e-03, -1.4137e-02],\n",
       "         [-1.9951e-03, -8.9569e-03, -2.3632e-03,  ..., -1.3733e-02,\n",
       "           1.3855e-02, -1.4687e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.weight': tensor([[ 0.0124, -0.0049, -0.0081,  ..., -0.0103,  0.0056,  0.0064],\n",
       "         [ 0.0060,  0.0029,  0.0042,  ...,  0.0127,  0.0080,  0.0138],\n",
       "         [ 0.0117,  0.0014, -0.0020,  ...,  0.0048,  0.0090, -0.0052],\n",
       "         ...,\n",
       "         [ 0.0147, -0.0089,  0.0013,  ...,  0.0044,  0.0118, -0.0114],\n",
       "         [ 0.0118,  0.0023, -0.0052,  ...,  0.0028,  0.0078, -0.0141],\n",
       "         [-0.0111, -0.0075, -0.0109,  ...,  0.0088,  0.0121,  0.0006]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight': tensor([[ 0.0121, -0.0154, -0.0058,  ..., -0.0006, -0.0057, -0.0027],\n",
       "         [-0.0081, -0.0069, -0.0087,  ...,  0.0128,  0.0045, -0.0091],\n",
       "         [-0.0062,  0.0021, -0.0025,  ...,  0.0106, -0.0067,  0.0056],\n",
       "         ...,\n",
       "         [ 0.0048,  0.0052, -0.0145,  ..., -0.0009, -0.0136, -0.0029],\n",
       "         [-0.0080,  0.0037,  0.0128,  ..., -0.0052, -0.0084, -0.0011],\n",
       "         [ 0.0072, -0.0036,  0.0023,  ..., -0.0039, -0.0010, -0.0149]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.weight': tensor([[ 0.0070,  0.0032,  0.0019,  ...,  0.0119,  0.0130, -0.0042],\n",
       "         [-0.0118,  0.0047,  0.0059,  ...,  0.0122,  0.0091, -0.0111],\n",
       "         [-0.0079,  0.0035,  0.0018,  ...,  0.0032,  0.0050,  0.0045],\n",
       "         ...,\n",
       "         [ 0.0149, -0.0124, -0.0060,  ..., -0.0007, -0.0049, -0.0035],\n",
       "         [ 0.0060,  0.0020,  0.0075,  ...,  0.0132, -0.0082, -0.0023],\n",
       "         [-0.0121,  0.0096,  0.0102,  ..., -0.0118,  0.0053,  0.0080]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.weight': tensor([[ 0.0033, -0.0131,  0.0104,  ..., -0.0044,  0.0151, -0.0112],\n",
       "         [ 0.0109,  0.0112, -0.0025,  ...,  0.0074,  0.0150,  0.0018],\n",
       "         [-0.0085, -0.0130, -0.0064,  ...,  0.0076,  0.0132, -0.0035],\n",
       "         ...,\n",
       "         [ 0.0030, -0.0090, -0.0106,  ...,  0.0046, -0.0032,  0.0037],\n",
       "         [-0.0101, -0.0052,  0.0119,  ..., -0.0064, -0.0049,  0.0071],\n",
       "         [ 0.0042,  0.0115,  0.0136,  ...,  0.0137, -0.0025,  0.0090]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.mlp.down_proj.lora_A.weight': tensor([[-0.0056,  0.0092, -0.0093,  ..., -0.0031, -0.0057, -0.0086],\n",
       "         [ 0.0084,  0.0006, -0.0034,  ..., -0.0053,  0.0004,  0.0006],\n",
       "         [ 0.0038,  0.0068,  0.0087,  ...,  0.0079,  0.0085,  0.0063],\n",
       "         ...,\n",
       "         [-0.0028,  0.0069,  0.0054,  ...,  0.0011, -0.0078,  0.0047],\n",
       "         [ 0.0045, -0.0073,  0.0022,  ...,  0.0063, -0.0055, -0.0016],\n",
       "         [-0.0075, -0.0089, -0.0038,  ...,  0.0071,  0.0059,  0.0033]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.mlp.up_proj.lora_A.weight': tensor([[ 0.0081, -0.0092, -0.0083,  ..., -0.0075, -0.0063, -0.0102],\n",
       "         [ 0.0033,  0.0039,  0.0155,  ..., -0.0117, -0.0075, -0.0043],\n",
       "         [ 0.0094, -0.0052, -0.0012,  ...,  0.0114,  0.0121,  0.0139],\n",
       "         ...,\n",
       "         [-0.0134, -0.0125,  0.0134,  ..., -0.0094, -0.0104, -0.0095],\n",
       "         [-0.0139,  0.0119,  0.0072,  ...,  0.0137,  0.0038,  0.0150],\n",
       "         [-0.0107,  0.0098,  0.0034,  ..., -0.0046, -0.0075, -0.0051]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.24.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight': tensor([[ 0.0096,  0.0152, -0.0100,  ...,  0.0058, -0.0139,  0.0131],\n",
       "         [-0.0064, -0.0008,  0.0129,  ..., -0.0078,  0.0150,  0.0105],\n",
       "         [-0.0057, -0.0008,  0.0052,  ...,  0.0098, -0.0102, -0.0143],\n",
       "         ...,\n",
       "         [ 0.0048, -0.0056, -0.0146,  ..., -0.0154,  0.0088,  0.0131],\n",
       "         [ 0.0133,  0.0097,  0.0123,  ...,  0.0041,  0.0144, -0.0122],\n",
       "         [-0.0041,  0.0036,  0.0108,  ...,  0.0114,  0.0077, -0.0122]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.weight': tensor([[-7.8125e-03,  1.4137e-02, -1.2856e-02,  ...,  1.2894e-03,\n",
       "          -1.2192e-02,  7.5579e-05],\n",
       "         [ 1.4091e-02, -5.7983e-04,  5.5504e-03,  ..., -1.4126e-05,\n",
       "          -1.1276e-02,  6.1531e-03],\n",
       "         [-3.1910e-03, -8.8043e-03, -6.5193e-03,  ..., -1.3580e-02,\n",
       "           9.4299e-03, -4.3774e-04],\n",
       "         ...,\n",
       "         [-7.3624e-03,  7.2021e-03,  3.6869e-03,  ...,  1.4778e-02,\n",
       "           1.5297e-02, -5.1079e-03],\n",
       "         [-4.7035e-03,  7.3586e-03, -1.6747e-03,  ...,  6.8741e-03,\n",
       "           1.4641e-02, -5.2643e-03],\n",
       "         [ 3.0231e-03,  6.3400e-03, -1.2100e-02,  ..., -4.6654e-03,\n",
       "          -2.3441e-03,  3.1281e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight': tensor([[-1.1414e-02, -6.2141e-03,  5.7182e-03,  ...,  1.0386e-03,\n",
       "          -6.6452e-03, -4.7913e-03],\n",
       "         [-4.7722e-03,  8.1329e-03, -1.4931e-02,  ..., -1.5392e-03,\n",
       "           6.7482e-03, -5.1727e-03],\n",
       "         [ 7.4539e-03,  4.7989e-03,  7.5836e-03,  ..., -4.9667e-03,\n",
       "           2.2221e-03, -2.6169e-03],\n",
       "         ...,\n",
       "         [ 1.4648e-02,  1.5572e-02,  1.3411e-05,  ...,  2.4605e-03,\n",
       "           1.2314e-02, -1.0056e-02],\n",
       "         [ 1.4671e-02,  3.4103e-03,  9.1782e-03,  ..., -1.0063e-02,\n",
       "          -1.5472e-02, -1.3786e-02],\n",
       "         [-3.5477e-03, -7.9346e-03,  8.8310e-04,  ...,  1.0025e-02,\n",
       "          -1.1047e-02,  1.2817e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.weight': tensor([[ 1.5251e-02,  8.9359e-04, -1.4954e-02,  ...,  6.3400e-03,\n",
       "           1.1658e-02,  1.0338e-02],\n",
       "         [ 1.0672e-03, -1.3588e-02,  4.7951e-03,  ...,  1.0178e-02,\n",
       "           7.8735e-03,  1.0124e-02],\n",
       "         [ 9.8877e-03, -9.3384e-03,  7.3051e-03,  ..., -2.0790e-03,\n",
       "          -1.1833e-02,  1.7233e-03],\n",
       "         ...,\n",
       "         [ 5.4550e-04, -1.3290e-02, -1.0738e-03,  ...,  2.4509e-03,\n",
       "           5.4474e-03,  8.6441e-03],\n",
       "         [ 7.6637e-03, -2.6047e-05, -7.3969e-05,  ..., -6.1073e-03,\n",
       "           3.4981e-03,  1.3054e-02],\n",
       "         [-1.5457e-02,  1.8990e-04, -3.9177e-03,  ..., -6.8665e-03,\n",
       "          -1.2962e-02, -1.2947e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.weight': tensor([[ 0.0035,  0.0013,  0.0112,  ...,  0.0008,  0.0016, -0.0042],\n",
       "         [ 0.0144, -0.0069,  0.0035,  ..., -0.0130, -0.0082, -0.0008],\n",
       "         [-0.0063,  0.0083, -0.0028,  ...,  0.0145, -0.0090,  0.0033],\n",
       "         ...,\n",
       "         [ 0.0115, -0.0077,  0.0126,  ...,  0.0133,  0.0027,  0.0146],\n",
       "         [ 0.0037,  0.0054, -0.0129,  ..., -0.0133, -0.0002,  0.0106],\n",
       "         [-0.0046,  0.0022, -0.0052,  ..., -0.0141, -0.0120, -0.0118]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.mlp.down_proj.lora_A.weight': tensor([[-0.0067, -0.0049,  0.0018,  ..., -0.0079, -0.0060,  0.0016],\n",
       "         [ 0.0052, -0.0035, -0.0059,  ...,  0.0064, -0.0027,  0.0080],\n",
       "         [-0.0051, -0.0082, -0.0092,  ...,  0.0033,  0.0077,  0.0013],\n",
       "         ...,\n",
       "         [-0.0048, -0.0052,  0.0064,  ..., -0.0024, -0.0046,  0.0061],\n",
       "         [ 0.0032,  0.0084,  0.0056,  ...,  0.0042,  0.0029,  0.0081],\n",
       "         [ 0.0006,  0.0007, -0.0063,  ..., -0.0085,  0.0008,  0.0064]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.mlp.up_proj.lora_A.weight': tensor([[ 1.1162e-02, -6.1302e-03, -6.5079e-03,  ..., -1.0254e-02,\n",
       "          -9.5129e-04, -3.6964e-03],\n",
       "         [ 9.3994e-03,  4.5891e-03, -1.4084e-02,  ..., -9.5444e-03,\n",
       "          -4.6043e-03, -3.1128e-03],\n",
       "         [-1.1711e-02,  6.6986e-03, -1.8988e-03,  ..., -1.2512e-02,\n",
       "           4.2772e-04,  1.4954e-02],\n",
       "         ...,\n",
       "         [ 1.0509e-03,  3.6030e-03, -1.2726e-02,  ..., -7.4923e-05,\n",
       "           1.3123e-02, -1.0643e-03],\n",
       "         [ 1.2344e-02, -1.0300e-02, -3.1471e-03,  ..., -8.8806e-03,\n",
       "          -1.0979e-02, -2.1629e-03],\n",
       "         [ 7.3776e-03, -1.1871e-02,  3.4142e-03,  ...,  2.8057e-03,\n",
       "          -3.2940e-03,  6.6986e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.25.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight': tensor([[ 0.0107, -0.0137, -0.0145,  ..., -0.0065,  0.0133, -0.0136],\n",
       "         [-0.0063, -0.0145,  0.0066,  ...,  0.0093,  0.0144, -0.0109],\n",
       "         [-0.0117,  0.0016, -0.0151,  ...,  0.0096,  0.0156, -0.0016],\n",
       "         ...,\n",
       "         [-0.0130, -0.0143, -0.0064,  ...,  0.0027,  0.0006,  0.0049],\n",
       "         [ 0.0149, -0.0143, -0.0041,  ...,  0.0044,  0.0100, -0.0105],\n",
       "         [ 0.0099,  0.0010, -0.0137,  ..., -0.0082, -0.0137,  0.0055]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.weight': tensor([[ 0.0029, -0.0129,  0.0155,  ...,  0.0150,  0.0152,  0.0064],\n",
       "         [-0.0061, -0.0040, -0.0035,  ...,  0.0079,  0.0110, -0.0097],\n",
       "         [ 0.0099,  0.0010,  0.0145,  ...,  0.0140,  0.0021, -0.0089],\n",
       "         ...,\n",
       "         [ 0.0076, -0.0110,  0.0113,  ..., -0.0143, -0.0061, -0.0047],\n",
       "         [-0.0005,  0.0142, -0.0052,  ...,  0.0023,  0.0130,  0.0075],\n",
       "         [-0.0009,  0.0058, -0.0082,  ...,  0.0112, -0.0066,  0.0053]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight': tensor([[ 1.3565e-02, -1.1909e-02, -8.0566e-03,  ..., -8.1253e-03,\n",
       "          -1.3908e-02,  1.3992e-02],\n",
       "         [ 5.0621e-03, -1.1429e-02, -3.3150e-03,  ...,  2.1267e-03,\n",
       "           1.6098e-03, -3.6144e-03],\n",
       "         [-4.0245e-03, -2.7895e-05, -1.1017e-02,  ..., -1.4160e-02,\n",
       "          -2.1152e-03, -4.2267e-03],\n",
       "         ...,\n",
       "         [-9.8572e-03, -3.5038e-03, -8.6899e-03,  ..., -1.3046e-02,\n",
       "           1.0597e-02,  1.2794e-02],\n",
       "         [-3.2063e-03,  1.3550e-02, -3.8738e-03,  ..., -6.1417e-03,\n",
       "           6.9885e-03,  2.1267e-03],\n",
       "         [ 9.5606e-04,  7.6790e-03,  1.1055e-02,  ...,  1.0786e-03,\n",
       "          -1.0080e-03,  1.4702e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.weight': tensor([[-0.0064, -0.0063,  0.0117,  ..., -0.0139,  0.0075,  0.0061],\n",
       "         [ 0.0071,  0.0021,  0.0017,  ..., -0.0144, -0.0057, -0.0044],\n",
       "         [-0.0087,  0.0121, -0.0068,  ..., -0.0074, -0.0140,  0.0078],\n",
       "         ...,\n",
       "         [ 0.0134, -0.0069, -0.0096,  ...,  0.0045,  0.0133,  0.0074],\n",
       "         [ 0.0096,  0.0127, -0.0108,  ...,  0.0056, -0.0075, -0.0015],\n",
       "         [ 0.0039,  0.0052, -0.0029,  ...,  0.0052, -0.0102, -0.0038]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.weight': tensor([[-0.0117, -0.0064,  0.0049,  ..., -0.0101, -0.0066, -0.0039],\n",
       "         [ 0.0133, -0.0138,  0.0130,  ..., -0.0021, -0.0109,  0.0088],\n",
       "         [ 0.0032, -0.0055,  0.0081,  ..., -0.0014, -0.0039,  0.0127],\n",
       "         ...,\n",
       "         [-0.0063, -0.0133, -0.0137,  ...,  0.0009, -0.0042,  0.0008],\n",
       "         [-0.0121, -0.0035,  0.0140,  ..., -0.0025,  0.0112, -0.0147],\n",
       "         [ 0.0094, -0.0011,  0.0103,  ..., -0.0128,  0.0127,  0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.mlp.down_proj.lora_A.weight': tensor([[ 0.0078, -0.0078, -0.0061,  ..., -0.0018,  0.0061, -0.0062],\n",
       "         [-0.0026, -0.0049, -0.0038,  ...,  0.0050, -0.0004, -0.0089],\n",
       "         [ 0.0019,  0.0044,  0.0061,  ..., -0.0012, -0.0019,  0.0014],\n",
       "         ...,\n",
       "         [-0.0001,  0.0047,  0.0078,  ..., -0.0070,  0.0081,  0.0044],\n",
       "         [-0.0020,  0.0006,  0.0075,  ...,  0.0063,  0.0025,  0.0063],\n",
       "         [-0.0012,  0.0028, -0.0079,  ..., -0.0056, -0.0086,  0.0035]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.mlp.up_proj.lora_A.weight': tensor([[-0.0051, -0.0027, -0.0135,  ...,  0.0035,  0.0036,  0.0068],\n",
       "         [-0.0114,  0.0066, -0.0037,  ..., -0.0058,  0.0088, -0.0082],\n",
       "         [ 0.0083, -0.0138, -0.0154,  ...,  0.0146, -0.0070,  0.0064],\n",
       "         ...,\n",
       "         [-0.0024, -0.0104, -0.0147,  ...,  0.0003,  0.0027, -0.0119],\n",
       "         [-0.0115, -0.0031,  0.0023,  ...,  0.0059, -0.0035, -0.0087],\n",
       "         [-0.0015,  0.0011,  0.0026,  ..., -0.0048,  0.0024, -0.0090]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.26.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight': tensor([[ 0.0147,  0.0135,  0.0019,  ..., -0.0027,  0.0063, -0.0091],\n",
       "         [ 0.0073, -0.0017,  0.0028,  ..., -0.0004,  0.0144, -0.0061],\n",
       "         [-0.0100,  0.0013,  0.0018,  ..., -0.0056, -0.0056,  0.0017],\n",
       "         ...,\n",
       "         [-0.0156, -0.0111,  0.0141,  ..., -0.0053,  0.0017, -0.0033],\n",
       "         [ 0.0052, -0.0101, -0.0112,  ..., -0.0091, -0.0081,  0.0139],\n",
       "         [-0.0114,  0.0081, -0.0068,  ...,  0.0113,  0.0107,  0.0052]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.weight': tensor([[ 0.0075, -0.0148, -0.0116,  ...,  0.0118,  0.0019, -0.0020],\n",
       "         [-0.0008,  0.0094, -0.0039,  ..., -0.0007,  0.0154,  0.0134],\n",
       "         [ 0.0018, -0.0081, -0.0015,  ...,  0.0145,  0.0044,  0.0028],\n",
       "         ...,\n",
       "         [-0.0014,  0.0064,  0.0139,  ...,  0.0029,  0.0078,  0.0145],\n",
       "         [ 0.0119,  0.0039,  0.0124,  ..., -0.0129, -0.0039, -0.0032],\n",
       "         [ 0.0099, -0.0065,  0.0068,  ...,  0.0060,  0.0135,  0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight': tensor([[-0.0113, -0.0032, -0.0017,  ...,  0.0080,  0.0006,  0.0138],\n",
       "         [-0.0023,  0.0068, -0.0026,  ...,  0.0094,  0.0119,  0.0040],\n",
       "         [-0.0110, -0.0119,  0.0112,  ...,  0.0030, -0.0067, -0.0129],\n",
       "         ...,\n",
       "         [-0.0037, -0.0066, -0.0118,  ..., -0.0045,  0.0059,  0.0021],\n",
       "         [-0.0027, -0.0080,  0.0137,  ..., -0.0128, -0.0100, -0.0131],\n",
       "         [-0.0075,  0.0137,  0.0112,  ...,  0.0132, -0.0091,  0.0023]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.weight': tensor([[-0.0085, -0.0124, -0.0085,  ...,  0.0106,  0.0034, -0.0065],\n",
       "         [ 0.0152,  0.0032,  0.0053,  ...,  0.0062,  0.0084, -0.0034],\n",
       "         [-0.0142,  0.0142,  0.0084,  ..., -0.0108, -0.0003, -0.0007],\n",
       "         ...,\n",
       "         [-0.0076,  0.0076,  0.0125,  ..., -0.0031, -0.0156,  0.0033],\n",
       "         [ 0.0045,  0.0046, -0.0078,  ..., -0.0039,  0.0077,  0.0112],\n",
       "         [-0.0128, -0.0082, -0.0060,  ..., -0.0059, -0.0031, -0.0059]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.weight': tensor([[ 0.0124, -0.0052,  0.0004,  ...,  0.0117,  0.0075,  0.0027],\n",
       "         [ 0.0147,  0.0144,  0.0096,  ...,  0.0064,  0.0093,  0.0145],\n",
       "         [-0.0099, -0.0001,  0.0043,  ..., -0.0067,  0.0004,  0.0044],\n",
       "         ...,\n",
       "         [-0.0131,  0.0098, -0.0055,  ...,  0.0107, -0.0072,  0.0042],\n",
       "         [ 0.0094, -0.0002,  0.0047,  ...,  0.0121, -0.0128,  0.0107],\n",
       "         [-0.0112, -0.0008,  0.0097,  ..., -0.0021, -0.0007, -0.0062]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.mlp.down_proj.lora_A.weight': tensor([[ 0.0072, -0.0086,  0.0060,  ..., -0.0018, -0.0081,  0.0071],\n",
       "         [ 0.0021,  0.0031, -0.0027,  ..., -0.0056, -0.0023, -0.0006],\n",
       "         [ 0.0075,  0.0034, -0.0003,  ..., -0.0084,  0.0011,  0.0053],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0006,  0.0057,  ...,  0.0059, -0.0060,  0.0010],\n",
       "         [-0.0009, -0.0044, -0.0083,  ...,  0.0061, -0.0057,  0.0093],\n",
       "         [-0.0068,  0.0025,  0.0080,  ...,  0.0093, -0.0059, -0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.mlp.up_proj.lora_A.weight': tensor([[-0.0132,  0.0066,  0.0090,  ..., -0.0022, -0.0077,  0.0005],\n",
       "         [ 0.0099,  0.0107, -0.0007,  ...,  0.0040,  0.0072, -0.0081],\n",
       "         [-0.0145,  0.0068, -0.0041,  ...,  0.0105, -0.0015, -0.0108],\n",
       "         ...,\n",
       "         [ 0.0133,  0.0024, -0.0140,  ..., -0.0120, -0.0125,  0.0062],\n",
       "         [-0.0155, -0.0070, -0.0068,  ..., -0.0152,  0.0078,  0.0069],\n",
       "         [ 0.0134,  0.0152,  0.0097,  ...,  0.0017,  0.0152,  0.0098]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.27.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight': tensor([[ 0.0105, -0.0113,  0.0068,  ...,  0.0079, -0.0131,  0.0129],\n",
       "         [-0.0150, -0.0009,  0.0014,  ..., -0.0014, -0.0028,  0.0036],\n",
       "         [-0.0025,  0.0029, -0.0138,  ...,  0.0122, -0.0064, -0.0076],\n",
       "         ...,\n",
       "         [ 0.0084, -0.0090,  0.0102,  ...,  0.0089, -0.0057, -0.0004],\n",
       "         [ 0.0140, -0.0046, -0.0122,  ...,  0.0064, -0.0089, -0.0026],\n",
       "         [ 0.0115,  0.0072, -0.0090,  ...,  0.0132, -0.0061,  0.0089]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.weight': tensor([[ 0.0028,  0.0075, -0.0005,  ..., -0.0103,  0.0005, -0.0091],\n",
       "         [ 0.0036, -0.0040,  0.0054,  ...,  0.0136, -0.0088,  0.0135],\n",
       "         [ 0.0051,  0.0143,  0.0041,  ..., -0.0095, -0.0030, -0.0087],\n",
       "         ...,\n",
       "         [-0.0002, -0.0039,  0.0096,  ...,  0.0123, -0.0040,  0.0134],\n",
       "         [-0.0009,  0.0076,  0.0072,  ..., -0.0031, -0.0011, -0.0005],\n",
       "         [-0.0133, -0.0021,  0.0046,  ...,  0.0137,  0.0006, -0.0156]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight': tensor([[-3.3474e-03, -2.3708e-03,  3.6659e-03,  ..., -1.3180e-03,\n",
       "          -8.5907e-03, -7.8201e-03],\n",
       "         [ 1.5121e-02, -4.7302e-03, -4.4048e-05,  ...,  1.1780e-02,\n",
       "          -6.1760e-03,  5.6534e-03],\n",
       "         [-1.2520e-02, -8.3160e-03,  1.1299e-02,  ...,  8.5297e-03,\n",
       "           8.6441e-03, -2.4452e-03],\n",
       "         ...,\n",
       "         [ 3.2539e-03,  8.3771e-03, -1.2947e-02,  ..., -2.9488e-03,\n",
       "          -1.4229e-02, -8.0872e-03],\n",
       "         [-7.0877e-03, -1.1230e-02, -5.2795e-03,  ..., -1.2627e-02,\n",
       "           9.2850e-03,  8.7280e-03],\n",
       "         [ 1.2016e-02,  8.7662e-03,  1.4648e-02,  ..., -6.5765e-03,\n",
       "          -1.1215e-02, -6.7329e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.weight': tensor([[-0.0086,  0.0125, -0.0095,  ..., -0.0101, -0.0035, -0.0079],\n",
       "         [ 0.0095,  0.0125, -0.0070,  ..., -0.0143, -0.0043, -0.0034],\n",
       "         [ 0.0055, -0.0141,  0.0065,  ..., -0.0123, -0.0066,  0.0090],\n",
       "         ...,\n",
       "         [-0.0152, -0.0110, -0.0020,  ...,  0.0106,  0.0009, -0.0061],\n",
       "         [ 0.0019,  0.0141,  0.0059,  ..., -0.0100, -0.0055, -0.0038],\n",
       "         [-0.0111, -0.0003,  0.0026,  ..., -0.0131, -0.0094,  0.0104]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.weight': tensor([[ 0.0092, -0.0114, -0.0121,  ..., -0.0103,  0.0095, -0.0097],\n",
       "         [-0.0099, -0.0118, -0.0092,  ..., -0.0024,  0.0108, -0.0117],\n",
       "         [-0.0139, -0.0096, -0.0107,  ..., -0.0021,  0.0044, -0.0079],\n",
       "         ...,\n",
       "         [-0.0151, -0.0141, -0.0106,  ...,  0.0016, -0.0151, -0.0130],\n",
       "         [ 0.0090, -0.0070,  0.0042,  ..., -0.0014,  0.0133, -0.0067],\n",
       "         [-0.0062,  0.0061,  0.0111,  ...,  0.0090,  0.0100, -0.0006]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.mlp.down_proj.lora_A.weight': tensor([[-0.0067, -0.0095, -0.0066,  ..., -0.0077,  0.0067, -0.0048],\n",
       "         [-0.0081,  0.0022,  0.0049,  ...,  0.0092,  0.0061,  0.0068],\n",
       "         [ 0.0004,  0.0092, -0.0019,  ..., -0.0067, -0.0032, -0.0095],\n",
       "         ...,\n",
       "         [ 0.0036,  0.0065, -0.0091,  ...,  0.0066, -0.0086,  0.0059],\n",
       "         [ 0.0061,  0.0021, -0.0058,  ..., -0.0034,  0.0013,  0.0078],\n",
       "         [ 0.0062, -0.0077, -0.0019,  ..., -0.0064, -0.0019,  0.0048]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.mlp.up_proj.lora_A.weight': tensor([[-9.0714e-03, -6.5308e-03,  2.8062e-04,  ...,  1.3466e-02,\n",
       "           9.1934e-03,  6.2790e-03],\n",
       "         [ 4.6043e-03, -1.4511e-02,  1.2688e-02,  ..., -9.1705e-03,\n",
       "          -6.8307e-05,  1.0086e-02],\n",
       "         [ 1.4053e-02,  1.0290e-03, -6.6147e-03,  ..., -2.7733e-03,\n",
       "          -4.4966e-04,  1.1606e-03],\n",
       "         ...,\n",
       "         [ 1.4771e-02,  8.0566e-03,  9.7885e-03,  ..., -4.2496e-03,\n",
       "           1.2268e-02,  3.7403e-03],\n",
       "         [-1.0269e-02, -8.5526e-03,  1.5305e-02,  ..., -1.1909e-02,\n",
       "           1.0880e-02,  1.4206e-02],\n",
       "         [-2.2163e-03,  1.0941e-02,  7.3013e-03,  ...,  1.1377e-03,\n",
       "          -6.9923e-03,  3.0422e-04]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.28.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight': tensor([[-0.0010,  0.0115,  0.0041,  ...,  0.0155, -0.0097, -0.0077],\n",
       "         [-0.0105, -0.0117,  0.0153,  ...,  0.0097,  0.0150, -0.0012],\n",
       "         [ 0.0150, -0.0047, -0.0045,  ..., -0.0057,  0.0066, -0.0089],\n",
       "         ...,\n",
       "         [-0.0061,  0.0122,  0.0043,  ...,  0.0091,  0.0115, -0.0109],\n",
       "         [ 0.0055,  0.0147, -0.0121,  ..., -0.0119,  0.0024,  0.0044],\n",
       "         [ 0.0117, -0.0108, -0.0082,  ...,  0.0133, -0.0018,  0.0146]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.weight': tensor([[-0.0014, -0.0114,  0.0072,  ..., -0.0054,  0.0109, -0.0076],\n",
       "         [-0.0149, -0.0095, -0.0025,  ..., -0.0093,  0.0082, -0.0002],\n",
       "         [-0.0013, -0.0013,  0.0080,  ...,  0.0145,  0.0024,  0.0062],\n",
       "         ...,\n",
       "         [ 0.0005, -0.0062,  0.0138,  ...,  0.0046, -0.0146,  0.0129],\n",
       "         [ 0.0134, -0.0121, -0.0049,  ...,  0.0045,  0.0145, -0.0130],\n",
       "         [ 0.0093, -0.0034, -0.0056,  ...,  0.0029,  0.0148, -0.0154]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight': tensor([[ 1.3321e-02, -1.4526e-02, -1.7941e-05,  ...,  1.2482e-02,\n",
       "           1.4524e-03,  3.7880e-03],\n",
       "         [-4.4670e-03, -1.7805e-03, -1.1711e-03,  ...,  1.4084e-02,\n",
       "          -4.6082e-03,  4.5242e-03],\n",
       "         [-8.3542e-04,  1.5419e-02,  1.3268e-02,  ...,  9.1705e-03,\n",
       "          -6.3210e-03, -8.7051e-03],\n",
       "         ...,\n",
       "         [ 5.1384e-03,  6.2408e-03, -9.8705e-04,  ...,  9.2239e-03,\n",
       "           7.6485e-04,  1.1848e-02],\n",
       "         [ 3.5286e-03,  1.1452e-02, -4.2191e-03,  ..., -1.4076e-02,\n",
       "          -9.4299e-03,  1.2016e-02],\n",
       "         [-2.4109e-03,  1.5594e-02, -1.0071e-03,  ...,  1.1940e-02,\n",
       "          -1.0384e-02,  7.7400e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.weight': tensor([[ 9.3689e-03, -7.3853e-03, -5.9204e-03,  ..., -9.3384e-03,\n",
       "           1.0544e-02,  1.2245e-02],\n",
       "         [ 6.1035e-03, -7.0419e-03, -4.1313e-03,  ..., -6.0234e-03,\n",
       "          -9.4452e-03,  2.1534e-03],\n",
       "         [-8.7433e-03, -6.2752e-03,  4.3945e-03,  ..., -1.0803e-02,\n",
       "           8.9340e-03,  1.9293e-03],\n",
       "         ...,\n",
       "         [ 5.1308e-03, -1.3985e-02,  1.4130e-02,  ..., -1.2154e-02,\n",
       "          -3.2349e-03, -1.3924e-02],\n",
       "         [ 8.3351e-04,  8.9264e-03, -1.5610e-02,  ...,  1.1414e-02,\n",
       "           9.6178e-04,  2.6569e-03],\n",
       "         [-4.8995e-05,  5.8212e-03, -9.9106e-03,  ...,  5.5275e-03,\n",
       "          -5.2261e-03, -8.3694e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.weight': tensor([[ 0.0049, -0.0058, -0.0039,  ..., -0.0086, -0.0083, -0.0035],\n",
       "         [ 0.0019,  0.0039,  0.0050,  ..., -0.0062,  0.0045, -0.0097],\n",
       "         [-0.0020, -0.0124, -0.0017,  ..., -0.0129,  0.0134,  0.0055],\n",
       "         ...,\n",
       "         [ 0.0018,  0.0080,  0.0041,  ...,  0.0041, -0.0131, -0.0146],\n",
       "         [ 0.0028, -0.0139,  0.0085,  ..., -0.0104,  0.0080,  0.0112],\n",
       "         [-0.0070,  0.0060,  0.0113,  ..., -0.0150,  0.0076,  0.0133]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.mlp.down_proj.lora_A.weight': tensor([[-0.0010, -0.0084,  0.0050,  ...,  0.0078, -0.0028, -0.0024],\n",
       "         [ 0.0080,  0.0081,  0.0033,  ...,  0.0016,  0.0076, -0.0005],\n",
       "         [-0.0058,  0.0070,  0.0089,  ..., -0.0042, -0.0083,  0.0025],\n",
       "         ...,\n",
       "         [-0.0090,  0.0092,  0.0050,  ..., -0.0058, -0.0054, -0.0082],\n",
       "         [ 0.0015,  0.0074, -0.0054,  ..., -0.0062,  0.0077,  0.0023],\n",
       "         [-0.0052, -0.0082,  0.0012,  ..., -0.0035, -0.0044, -0.0057]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.mlp.up_proj.lora_A.weight': tensor([[-0.0017,  0.0042, -0.0124,  ..., -0.0054,  0.0130,  0.0019],\n",
       "         [ 0.0020, -0.0134,  0.0072,  ..., -0.0083,  0.0075,  0.0031],\n",
       "         [ 0.0098,  0.0144,  0.0009,  ..., -0.0083,  0.0105,  0.0059],\n",
       "         ...,\n",
       "         [ 0.0112, -0.0076, -0.0015,  ...,  0.0016,  0.0156, -0.0107],\n",
       "         [-0.0022, -0.0009, -0.0141,  ...,  0.0116,  0.0087, -0.0091],\n",
       "         [-0.0101, -0.0102, -0.0003,  ..., -0.0135,  0.0136,  0.0033]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.29.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight': tensor([[ 0.0094, -0.0114, -0.0106,  ...,  0.0061,  0.0080, -0.0089],\n",
       "         [ 0.0118, -0.0105, -0.0101,  ...,  0.0151, -0.0137,  0.0125],\n",
       "         [ 0.0023,  0.0053,  0.0127,  ...,  0.0125,  0.0025, -0.0043],\n",
       "         ...,\n",
       "         [-0.0019, -0.0107,  0.0108,  ...,  0.0109, -0.0128,  0.0111],\n",
       "         [ 0.0106, -0.0016,  0.0062,  ..., -0.0101, -0.0020,  0.0094],\n",
       "         [ 0.0052, -0.0148, -0.0091,  ..., -0.0136,  0.0127,  0.0090]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.weight': tensor([[ 0.0034, -0.0093,  0.0050,  ..., -0.0123, -0.0079, -0.0070],\n",
       "         [ 0.0092, -0.0143,  0.0041,  ...,  0.0002,  0.0003,  0.0084],\n",
       "         [-0.0117, -0.0015, -0.0015,  ...,  0.0003, -0.0010, -0.0029],\n",
       "         ...,\n",
       "         [-0.0041,  0.0137,  0.0123,  ...,  0.0073, -0.0021, -0.0064],\n",
       "         [-0.0148,  0.0091, -0.0131,  ...,  0.0078, -0.0156,  0.0085],\n",
       "         [ 0.0131, -0.0074,  0.0129,  ..., -0.0049, -0.0131,  0.0049]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight': tensor([[-0.0145,  0.0029, -0.0125,  ...,  0.0098, -0.0145,  0.0105],\n",
       "         [ 0.0012, -0.0007,  0.0144,  ..., -0.0115, -0.0080, -0.0027],\n",
       "         [ 0.0055,  0.0034, -0.0104,  ..., -0.0046,  0.0143, -0.0014],\n",
       "         ...,\n",
       "         [-0.0109,  0.0008,  0.0118,  ..., -0.0062,  0.0096,  0.0037],\n",
       "         [ 0.0123, -0.0111,  0.0007,  ..., -0.0076,  0.0124, -0.0033],\n",
       "         [ 0.0011, -0.0007, -0.0079,  ..., -0.0085,  0.0133,  0.0150]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.weight': tensor([[ 0.0104, -0.0088, -0.0025,  ...,  0.0154,  0.0053, -0.0067],\n",
       "         [-0.0079,  0.0050,  0.0116,  ..., -0.0103, -0.0073,  0.0027],\n",
       "         [-0.0014,  0.0016,  0.0137,  ...,  0.0023, -0.0121,  0.0140],\n",
       "         ...,\n",
       "         [-0.0104,  0.0003, -0.0051,  ..., -0.0089, -0.0128,  0.0114],\n",
       "         [ 0.0085, -0.0083, -0.0068,  ..., -0.0123, -0.0020,  0.0079],\n",
       "         [-0.0039, -0.0120,  0.0061,  ..., -0.0015, -0.0061, -0.0086]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.weight': tensor([[-0.0039, -0.0078, -0.0084,  ...,  0.0094, -0.0034,  0.0124],\n",
       "         [-0.0029, -0.0037,  0.0027,  ..., -0.0007,  0.0013,  0.0082],\n",
       "         [ 0.0083,  0.0129,  0.0067,  ...,  0.0087,  0.0100,  0.0143],\n",
       "         ...,\n",
       "         [ 0.0034,  0.0062,  0.0122,  ..., -0.0073,  0.0074,  0.0106],\n",
       "         [ 0.0031,  0.0099, -0.0112,  ...,  0.0073,  0.0086, -0.0149],\n",
       "         [-0.0117,  0.0003,  0.0017,  ...,  0.0105, -0.0075, -0.0094]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.mlp.down_proj.lora_A.weight': tensor([[ 0.0051, -0.0064, -0.0088,  ..., -0.0052, -0.0092, -0.0047],\n",
       "         [-0.0087,  0.0020, -0.0064,  ...,  0.0018, -0.0052,  0.0074],\n",
       "         [-0.0029,  0.0082, -0.0026,  ...,  0.0059, -0.0068,  0.0013],\n",
       "         ...,\n",
       "         [-0.0019,  0.0081, -0.0060,  ..., -0.0051, -0.0002,  0.0076],\n",
       "         [ 0.0052,  0.0071, -0.0007,  ..., -0.0028, -0.0011, -0.0084],\n",
       "         [ 0.0002,  0.0010,  0.0054,  ..., -0.0029, -0.0010, -0.0080]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.mlp.up_proj.lora_A.weight': tensor([[ 0.0104, -0.0137,  0.0027,  ..., -0.0089, -0.0106, -0.0051],\n",
       "         [-0.0014, -0.0053, -0.0026,  ..., -0.0062,  0.0013,  0.0094],\n",
       "         [ 0.0035, -0.0012,  0.0103,  ...,  0.0146,  0.0153, -0.0073],\n",
       "         ...,\n",
       "         [-0.0005,  0.0063,  0.0077,  ...,  0.0023,  0.0100, -0.0062],\n",
       "         [-0.0093,  0.0089,  0.0114,  ..., -0.0110, -0.0056,  0.0006],\n",
       "         [ 0.0086,  0.0108,  0.0047,  ..., -0.0125,  0.0072, -0.0147]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.30.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight': tensor([[ 3.8433e-03,  8.5907e-03, -4.9248e-03,  ..., -3.4409e-03,\n",
       "           2.2392e-03,  2.9111e-04],\n",
       "         [ 1.4397e-02, -5.3883e-04,  4.2953e-03,  ..., -2.0084e-03,\n",
       "           3.2654e-03,  5.5618e-03],\n",
       "         [ 9.0790e-03,  1.0010e-02,  8.7128e-03,  ...,  1.2871e-02,\n",
       "           9.7885e-03, -2.0580e-03],\n",
       "         ...,\n",
       "         [ 1.3763e-02,  1.1986e-02, -4.3869e-03,  ...,  1.2543e-02,\n",
       "           8.1024e-03,  1.1063e-02],\n",
       "         [-2.5730e-03,  1.0757e-02, -1.1276e-02,  ..., -9.9106e-03,\n",
       "          -1.2207e-02,  1.5404e-02],\n",
       "         [-7.8812e-03,  3.6359e-05,  1.4908e-02,  ...,  8.0643e-03,\n",
       "          -7.9575e-03, -8.9722e-03]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.weight': tensor([[ 0.0029, -0.0147,  0.0089,  ..., -0.0131, -0.0132,  0.0093],\n",
       "         [-0.0054,  0.0146,  0.0093,  ...,  0.0016,  0.0060,  0.0095],\n",
       "         [-0.0062,  0.0156, -0.0041,  ..., -0.0073, -0.0033,  0.0018],\n",
       "         ...,\n",
       "         [-0.0021,  0.0013, -0.0142,  ..., -0.0070,  0.0072,  0.0041],\n",
       "         [-0.0090, -0.0046,  0.0016,  ...,  0.0035,  0.0147, -0.0074],\n",
       "         [ 0.0099,  0.0005,  0.0153,  ...,  0.0135,  0.0074,  0.0002]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight': tensor([[-0.0148,  0.0154, -0.0079,  ...,  0.0065,  0.0153,  0.0086],\n",
       "         [-0.0079,  0.0041, -0.0012,  ..., -0.0014,  0.0052, -0.0148],\n",
       "         [-0.0138, -0.0112, -0.0153,  ..., -0.0013,  0.0070,  0.0057],\n",
       "         ...,\n",
       "         [-0.0022,  0.0143, -0.0045,  ...,  0.0012,  0.0115, -0.0077],\n",
       "         [-0.0109, -0.0117, -0.0076,  ..., -0.0136, -0.0018,  0.0098],\n",
       "         [-0.0002, -0.0015, -0.0044,  ...,  0.0037, -0.0085,  0.0101]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.weight': tensor([[-0.0088,  0.0073, -0.0058,  ...,  0.0074, -0.0102,  0.0064],\n",
       "         [-0.0060, -0.0112,  0.0053,  ..., -0.0060,  0.0098,  0.0028],\n",
       "         [-0.0148,  0.0095,  0.0059,  ...,  0.0066, -0.0095, -0.0145],\n",
       "         ...,\n",
       "         [-0.0153,  0.0070,  0.0119,  ..., -0.0014, -0.0092,  0.0034],\n",
       "         [-0.0011, -0.0074,  0.0096,  ...,  0.0088,  0.0082, -0.0145],\n",
       "         [ 0.0012,  0.0003, -0.0153,  ..., -0.0151,  0.0143, -0.0090]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.weight': tensor([[ 1.1070e-02,  8.4610e-03,  5.1765e-03,  ...,  5.3749e-03,\n",
       "          -1.1833e-02, -1.3786e-02],\n",
       "         [ 1.3130e-02, -4.5929e-03, -1.9321e-03,  ...,  4.8676e-03,\n",
       "           2.0421e-04,  9.9869e-03],\n",
       "         [-5.7983e-03,  3.7804e-03,  1.0803e-02,  ...,  7.7858e-03,\n",
       "           4.9477e-03,  1.2177e-02],\n",
       "         ...,\n",
       "         [-1.1551e-02, -4.6802e-04, -6.3896e-03,  ..., -7.9880e-03,\n",
       "          -6.3820e-03, -8.7585e-03],\n",
       "         [-3.6926e-03,  1.0788e-02, -3.2291e-03,  ..., -1.2665e-02,\n",
       "          -8.3084e-03, -1.0742e-02],\n",
       "         [ 3.7551e-04,  9.3994e-03,  5.7106e-03,  ...,  1.8299e-05,\n",
       "          -1.3672e-02,  1.4305e-02]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.mlp.down_proj.lora_A.weight': tensor([[-0.0035, -0.0008,  0.0059,  ..., -0.0092,  0.0061, -0.0006],\n",
       "         [ 0.0064, -0.0049,  0.0058,  ...,  0.0065,  0.0057,  0.0094],\n",
       "         [-0.0056, -0.0054, -0.0036,  ..., -0.0021,  0.0062,  0.0040],\n",
       "         ...,\n",
       "         [ 0.0010,  0.0002,  0.0027,  ..., -0.0022, -0.0084,  0.0093],\n",
       "         [-0.0027, -0.0020, -0.0028,  ..., -0.0023, -0.0079,  0.0095],\n",
       "         [-0.0034,  0.0014,  0.0014,  ..., -0.0002,  0.0057,  0.0077]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.mlp.down_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.mlp.up_proj.lora_A.weight': tensor([[-0.0006,  0.0060, -0.0075,  ...,  0.0025,  0.0028,  0.0050],\n",
       "         [ 0.0015, -0.0094, -0.0126,  ...,  0.0034, -0.0116,  0.0136],\n",
       "         [-0.0098,  0.0007,  0.0148,  ...,  0.0054, -0.0004,  0.0040],\n",
       "         ...,\n",
       "         [-0.0153, -0.0026, -0.0149,  ..., -0.0131, -0.0028, -0.0064],\n",
       "         [-0.0049, -0.0083, -0.0019,  ..., -0.0124, -0.0001, -0.0105],\n",
       "         [-0.0102, -0.0124, -0.0010,  ..., -0.0031,  0.0008, -0.0094]],\n",
       "        dtype=torch.float16),\n",
       " 'base_model.model.model.layers.31.mlp.up_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(torch.load('/nfs/a100-006/hanweiguang/saved_model/boxue_1_bs-8_lr-3e-4_wm-1e-2_epoch-10_lora/adapter_model.bin').values())[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lora_parameters.values())[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
